{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from stu import STU\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lds import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "_ = plt.hist(exponential_decay_init([1000], lam = 3), bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class LDS_LR(nn.Module):\n",
    "    def __init__(self, state_dim, input_dim, output_dim, kx=5, rank = 50, lam = 1):\n",
    "        super(LDS_LR, self).__init__()\n",
    "        self.state_dim = state_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.kx = kx\n",
    "        self.h0 = nn.Parameter(torch.randn(state_dim))\n",
    "        \n",
    "        self.A = nn.Parameter(exponential_decay_init([state_dim], lam = lam))\n",
    "\n",
    "        self.B1 = nn.Parameter(torch.randn(input_dim, rank) / input_dim) #each of these ranks could be different\n",
    "        self.B2   = nn.Parameter(torch.randn(rank, state_dim) / math.sqrt(rank))\n",
    "\n",
    "        self.C1 = nn.Parameter(torch.randn(state_dim, rank) / state_dim)\n",
    "        self.C2   = nn.Parameter(torch.randn(rank, output_dim) / math.sqrt(rank))\n",
    "\n",
    "        self.M2 = nn.Parameter(torch.randn(output_dim, rank, kx) / output_dim)\n",
    "        self.M1   = nn.Parameter(torch.randn(rank, input_dim, kx) / math.sqrt(rank))\n",
    "    \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        device = inputs.device\n",
    "        bsz, seq_len, _ = inputs.shape\n",
    "        h_t = self.h0.expand(bsz, self.state_dim).to(device)\n",
    "        A = self.A.flatten()\n",
    "        \n",
    "        all_h_t = []\n",
    "        for t in range(seq_len):\n",
    "            u_t = inputs[:, t, :]\n",
    "            h_t = A * h_t + ((u_t @ self.B1) @ self.B2)\n",
    "            all_h_t.append(h_t.unsqueeze(1))\n",
    "        all_h_t = torch.cat(all_h_t, dim=1)\n",
    "        lds_out = torch.matmul(all_h_t, self.C1)\n",
    "        lds_out = torch.matmul(lds_out, self.C2)\n",
    "\n",
    "        ar = compute_ar_x_preds(self.M1, inputs)\n",
    "        ar = compute_ar_x_preds(self.M2, ar)\n",
    "        return lds_out + ar\n",
    "\n",
    "    def compute_loss(self, inputs, targets):\n",
    "        mse_loss = nn.MSELoss()\n",
    "        outputs = self(inputs)\n",
    "        return mse_loss(outputs, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2729773/936017912.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  stu_layer_full = torch.load(f\"../stu_layers/stu_layer_{layer_i}_500m_param_full.pt\", map_location=device)\n"
     ]
    }
   ],
   "source": [
    "layer_i = 0\n",
    "state_dim = 10000\n",
    "batch_size = 2\n",
    "epochs = 4000\n",
    "seq_len = 512\n",
    "kx = 3\n",
    "lam = 1\n",
    "lr = 0.0001\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the layer i weights\n",
    "stu_layer_full = torch.load(f\"../stu_layers/stu_layer_{layer_i}_500m_param_full.pt\", map_location=device)\n",
    "stu_layer_full.to(device)\n",
    "\n",
    "# Initialize LDS model\n",
    "# lds = LDS_LR(state_dim, 768, 768, kx, rank = 50, lam = lam).to(device)\n",
    "lds = LDS(state_dim, 768, 768, kx, lam = lam).to(device)\n",
    "optimizer = torch.optim.Adam(lds.parameters(), lr=lr)\n",
    "\n",
    "# Training\n",
    "lds_loss_values = []\n",
    "\n",
    "best_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.10265550017356873\n",
      "Epoch 10, Loss: 0.08941756933927536\n",
      "Epoch 20, Loss: 0.0740121379494667\n",
      "Epoch 30, Loss: 0.05623256415128708\n",
      "Epoch 40, Loss: 0.03878938406705856\n",
      "Epoch 50, Loss: 0.024538924917578697\n",
      "Epoch 60, Loss: 0.014576549641788006\n",
      "Epoch 70, Loss: 0.00902007706463337\n",
      "Epoch 80, Loss: 0.006022542715072632\n",
      "Epoch 90, Loss: 0.004336541052907705\n",
      "Epoch 100, Loss: 0.0033186457585543394\n",
      "Epoch 110, Loss: 0.002526800613850355\n",
      "Epoch 120, Loss: 0.0020581744611263275\n",
      "Epoch 130, Loss: 0.0017126929014921188\n",
      "Epoch 140, Loss: 0.001462268177419901\n",
      "Epoch 150, Loss: 0.0012430476490408182\n",
      "Epoch 160, Loss: 0.0011002897517755628\n",
      "Epoch 170, Loss: 0.000987514271400869\n",
      "Epoch 180, Loss: 0.0008791509899310768\n",
      "Epoch 190, Loss: 0.0008146673208102584\n",
      "Epoch 200, Loss: 0.0007501497748307884\n",
      "Epoch 210, Loss: 0.0007110795704647899\n",
      "Epoch 220, Loss: 0.0006718254880979657\n",
      "Epoch 230, Loss: 0.0006268477300181985\n",
      "Epoch 240, Loss: 0.0006020250148139894\n",
      "Epoch 250, Loss: 0.0005680245230905712\n",
      "Epoch 260, Loss: 0.0005360440700314939\n",
      "Epoch 270, Loss: 0.0005160801229067147\n",
      "Epoch 280, Loss: 0.0005057086236774921\n",
      "Epoch 290, Loss: 0.0004807128570973873\n",
      "Epoch 300, Loss: 0.0004662225837819278\n",
      "Epoch 310, Loss: 0.0004486427642405033\n",
      "Epoch 320, Loss: 0.00042932372889481485\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      6\u001b[0m loss \u001b[38;5;241m=\u001b[39m lds\u001b[38;5;241m.\u001b[39mcompute_loss(inputs\u001b[38;5;241m.\u001b[39mto(stu_outputs\u001b[38;5;241m.\u001b[39mdtype), stu_outputs)\n\u001b[0;32m----> 7\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# torch.nn.utils.clip_grad_norm_(lds.parameters(), max_norm=1)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m lds_loss_values\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/.conda/envs/torch-env/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    583\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/torch-env/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[1;32m    348\u001b[0m     tensors,\n\u001b[1;32m    349\u001b[0m     grad_tensors_,\n\u001b[1;32m    350\u001b[0m     retain_graph,\n\u001b[1;32m    351\u001b[0m     create_graph,\n\u001b[1;32m    352\u001b[0m     inputs,\n\u001b[1;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/torch-env/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    inputs = torch.randn(batch_size, seq_len, 768).to(device).to(torch.bfloat16)\n",
    "    stu_outputs = stu_layer_full(inputs).to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = lds.compute_loss(inputs.to(stu_outputs.dtype), stu_outputs)\n",
    "    loss.backward()\n",
    "    # torch.nn.utils.clip_grad_norm_(lds.parameters(), max_norm=1)\n",
    "    lds_loss_values.append(loss.item())\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        lds.A.data.clamp_(max=1, min=-1)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "#With LDS_LR at rank = 50, kx = 3, state = 10k, lam = 1 after 100 epochs loss is 0.090, 200 is 0.088, 300 is 0.086\n",
    "#With LDS_LR at rank = 300, kx = 3, state = 10k, lam = 1 after 100 epochs loss is 0.058, 200 is 0.032, 300 loss is 0.023\n",
    "#With LDS_LR at rank = 768, kx = 3, state = 10k, lam = 1 after 100 epochs loss is 0.014, 200 is 0.00369, 300 loss is 0.00168\n",
    "\n",
    "#With LDS at rank = 768, kx = 3, state = 10k, lam = 1 after 100 epochs loss is 0.0033, 200 is 0.00075, 300 loss is 0.00047"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env [~/.conda/envs/torch-env/]",
   "language": "python",
   "name": "conda_torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
