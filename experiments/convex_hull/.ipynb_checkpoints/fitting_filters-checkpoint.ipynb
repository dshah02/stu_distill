{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../../src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from stu import STU\n",
    "import time\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lds import LDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hankel(seq_len: int, use_hankel_L: bool = False) -> np.ndarray:\n",
    "    entries = np.arange(1, seq_len + 1, dtype=np.float64)\n",
    "    i_plus_j = entries[:, None] + entries[None, :]\n",
    "\n",
    "    if use_hankel_L:\n",
    "        sgn = (-1.0) ** (i_plus_j - 2.0) + 1.0\n",
    "        denom = (i_plus_j + 3.0) * (i_plus_j - 1.0) * (i_plus_j + 1.0)\n",
    "        Z = sgn * (8.0 / denom)\n",
    "    elif not use_hankel_L:\n",
    "        Z = 2.0 / (i_plus_j**3 - i_plus_j)\n",
    "    else:\n",
    "        raise ValueError(\"use_hankel_L must be a boolean\")\n",
    "\n",
    "    return Z\n",
    "\n",
    "def get_spectral_filters(\n",
    "    seq_len: int,\n",
    "    K: int,\n",
    "    use_hankel_L: bool = False,\n",
    "    device: torch.device = None,\n",
    "    dtype: torch.dtype = torch.bfloat16,\n",
    ") -> torch.Tensor:\n",
    "    # assert torch.cuda.is_available(), \"CUDA is required.\"\n",
    "    Z = get_hankel(seq_len, use_hankel_L)\n",
    "    sigma, phi = np.linalg.eigh(Z)\n",
    "    sigma_k, phi_k = sigma[-K:], phi[:, -K:]\n",
    "    phi_k *= sigma_k ** 0.25\n",
    "    filters = torch.from_numpy(phi_k)\n",
    "    return filters.to(device=device, dtype=dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_i = 0\n",
    "state_dim = 5000\n",
    "batch_size = 2\n",
    "epochs = 4000\n",
    "seq_len = 512\n",
    "kx = 5\n",
    "lr = 0.0001\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seq_len = 4096\n",
    "num_eigh = 30\n",
    "use_hankel_L  = True\n",
    "phi= get_spectral_filters(seq_len = seq_len, K = num_eigh,  use_hankel_L= use_hankel_L,\n",
    "                                device  = device,  dtype = torch.float32)\n",
    "\n",
    "stu_config = {\n",
    "    \"num_eigh\": num_eigh,\n",
    "    \"use_hankel_L\": True,\n",
    "    \"torch_dtype\": torch.float32,\n",
    "    \"d_in\": 1,\n",
    "    \"d_out\": 1,\n",
    "    \"seq_len\": seq_len,\n",
    "    \"k_u\": 0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LDS model\n",
    "lds = LDS(state_dim, 768, 768, kx).to(device)\n",
    "optimizer = torch.optim.Adam(lds.parameters(), lr=lr)\n",
    "\n",
    "# Training\n",
    "lds_loss_values = []\n",
    "\n",
    "best_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basic_stu import STU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_0 = STU(stu_config, phi).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_0.M_phi_minus.data = torch.zeros_like(phi_0.M_phi_minus)\n",
    "phi_0.M_phi_plus.data = torch.zeros_like(phi_0.M_phi_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_0.M_phi_plus[0][0][0].data = torch.tensor(1.0, requires_grad= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.81 GiB. GPU 0 has a total capacity of 9.50 GiB of which 2.30 GiB is free. Process 586991 has 7.16 GiB memory in use. Process 1491827 has 5.83 GiB memory in use. Process 3103330 has 700.00 MiB memory in use. Process 3102972 has 910.00 MiB memory in use. Process 3103824 has 932.00 MiB memory in use. Process 3102973 has 910.00 MiB memory in use. Including non-PyTorch memory, this process has 7.15 GiB memory in use. Of the allocated memory 5.69 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      2\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, seq_len, \u001b[38;5;241m768\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mbfloat16)\n\u001b[0;32m----> 3\u001b[0m     stu_outputs \u001b[38;5;241m=\u001b[39m phi_0(inputs)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      6\u001b[0m     loss \u001b[38;5;241m=\u001b[39m lds\u001b[38;5;241m.\u001b[39mcompute_loss(inputs\u001b[38;5;241m.\u001b[39mto(stu_outputs\u001b[38;5;241m.\u001b[39mdtype), stu_outputs)\n",
      "File \u001b[0;32m~/.conda/envs/torch-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/torch-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/stu_distill/src/basic_stu.py:93\u001b[0m, in \u001b[0;36mSTU.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     91\u001b[0m \n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# Convolve inputs and filters,\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     U_plus, U_minus \u001b[38;5;241m=\u001b[39m convolve(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphi, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# Then, contract over the K and d_in dimensions\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# print(U_plus.shape, U_minus.shape)\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     spectral_plus \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensordot(\n\u001b[1;32m     98\u001b[0m         U_plus, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM_phi_plus, dims\u001b[38;5;241m=\u001b[39m([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m], [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     99\u001b[0m     )\n",
      "File \u001b[0;32m~/stu_distill/src/basic_stu.py:58\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(u, v, n, use_approx)\u001b[0m\n\u001b[1;32m     56\u001b[0m v \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39mrfft(v, n\u001b[38;5;241m=\u001b[39mn, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     57\u001b[0m U \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([u, u \u001b[38;5;241m*\u001b[39m sgn], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 58\u001b[0m U \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39mrfft(U, n\u001b[38;5;241m=\u001b[39mn, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     59\u001b[0m U_conv \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39mirfft(v \u001b[38;5;241m*\u001b[39m U, n\u001b[38;5;241m=\u001b[39mn, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, :seq_len]\n\u001b[1;32m     60\u001b[0m U_plus, U_minus \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munbind(U_conv, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.81 GiB. GPU 0 has a total capacity of 9.50 GiB of which 2.30 GiB is free. Process 586991 has 7.16 GiB memory in use. Process 1491827 has 5.83 GiB memory in use. Process 3103330 has 700.00 MiB memory in use. Process 3102972 has 910.00 MiB memory in use. Process 3103824 has 932.00 MiB memory in use. Process 3102973 has 910.00 MiB memory in use. Including non-PyTorch memory, this process has 7.15 GiB memory in use. Of the allocated memory 5.69 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    inputs = torch.randn(batch_size, seq_len, 768).to(device).to(torch.bfloat16)\n",
    "    stu_outputs = phi_0(inputs).to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = lds.compute_loss(inputs.to(stu_outputs.dtype), stu_outputs)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(lds.parameters(), max_norm=1)\n",
    "    lds_loss_values.append(loss.item())\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        lds.A.data.clamp_(max=1, min=-1)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env [~/.conda/envs/torch-env/]",
   "language": "python",
   "name": "conda_torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
