{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading the checkpoint...\n",
      "Successfully loaded the checkpoint in 0.87 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tiktoken\n",
    "import logging\n",
    "import json\n",
    "from time import time\n",
    "from safetensors import safe_open\n",
    "from model import FlashSTU\n",
    "from config import FlashSTUConfig\n",
    "import torch.nn as nn\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "def get_hankel(seq_len: int, use_hankel_L: bool = False) -> np.ndarray:\n",
    "    entries = np.arange(1, seq_len + 1, dtype=np.float64)\n",
    "    i_plus_j = entries[:, None] + entries[None, :]\n",
    "\n",
    "    if use_hankel_L:\n",
    "        sgn = (-1.0) ** (i_plus_j - 2.0) + 1.0\n",
    "        denom = (i_plus_j + 3.0) * (i_plus_j - 1.0) * (i_plus_j + 1.0)\n",
    "        Z = sgn * (8.0 / denom)\n",
    "    elif not use_hankel_L:\n",
    "        Z = 2.0 / (i_plus_j**3 - i_plus_j)\n",
    "    else:\n",
    "        raise ValueError(\"use_hankel_L must be a boolean\")\n",
    "\n",
    "    return Z\n",
    "\n",
    "def get_spectral_filters(\n",
    "    seq_len: int, \n",
    "    K: int, \n",
    "    use_hankel_L: bool = False, \n",
    "    device: torch.device = None,\n",
    "    dtype: torch.dtype = torch.bfloat16,\n",
    ") -> torch.Tensor:\n",
    "    assert torch.cuda.is_available(), \"CUDA is required.\"\n",
    "    Z = get_hankel(seq_len, use_hankel_L)\n",
    "    sigma, phi = np.linalg.eigh(Z)\n",
    "    sigma_k, phi_k = sigma[-K:], phi[:, -K:]\n",
    "    phi_k *= sigma_k ** 0.25\n",
    "    filters = torch.from_numpy(phi_k)\n",
    "    return filters.to(device=device, dtype=dtype)\n",
    "\n",
    "# Load the checkpoint\n",
    "print(\"Loading the checkpoint...\")\n",
    "start_time = time()\n",
    "state_dict = {}\n",
    "with safe_open(\n",
    "    \"model_19073.safetensors\",\n",
    "    framework=\"pt\",\n",
    "    device=\"cuda\",\n",
    ") as f:\n",
    "    for k in f.keys():\n",
    "        state_dict[k] = f.get_tensor(k)\n",
    "\n",
    "print(f\"Successfully loaded the checkpoint in {time() - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Parameter Count: 426.28M\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set precision for matrix multiplication\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "# Load model configurations from JSON file\n",
    "with open(\"config.json\", \"r\") as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "# Extract model configurations\n",
    "n_embd = config[\"n_embd\"]\n",
    "n_heads = config[\"n_heads\"]\n",
    "n_layers = config[\"n_layers\"]\n",
    "seq_len = config[\"seq_len\"]\n",
    "window_size = config[\"window_size\"]\n",
    "vocab_size = config[\"vocab_size\"]\n",
    "mlp_scale = config[\"mlp_scale\"]\n",
    "bias = config[\"bias\"]\n",
    "dropout = config[\"dropout\"]\n",
    "num_eigh = config[\"num_eigh\"]\n",
    "use_hankel_L = config[\"use_hankel_L\"]\n",
    "use_flash_fft = config[\"use_flash_fft\"]\n",
    "use_approx = config[\"use_approx\"]\n",
    "use_attn = config[\"use_attn\"]\n",
    "softcap = config[\"softcap\"]\n",
    "\n",
    "# Model setup\n",
    "config = FlashSTUConfig(\n",
    "    n_embd=n_embd,\n",
    "    n_heads=n_heads,\n",
    "    n_layers=n_layers,\n",
    "    seq_len=seq_len,\n",
    "    window_size=window_size,\n",
    "    vocab_size=vocab_size,\n",
    "    mlp_scale=mlp_scale,\n",
    "    bias=bias,\n",
    "    dropout=dropout,\n",
    "    num_eigh=num_eigh,\n",
    "    use_hankel_L=use_hankel_L,\n",
    "    use_flash_fft=use_flash_fft,\n",
    "    use_approx=use_approx,\n",
    "    use_attn=use_attn,\n",
    "    softcap=softcap,\n",
    "    torch_dtype=getattr(torch, config[\"torch_dtype\"]),\n",
    ")\n",
    "phi = get_spectral_filters(seq_len, num_eigh, use_hankel_L, device, torch.float32)\n",
    "model = FlashSTU(config, phi)\n",
    "\n",
    "# Load state dictionary into the model\n",
    "model.load_state_dict(state_dict, strict = True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Prepare tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"o200k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def generate_text(\n",
    "    model, tokenizer, prompt, num_return_sequences=4, max_length=1024, device=\"cuda\", temperature=1.0, top_k=50\n",
    "):\n",
    "    model.eval()\n",
    "    tokens = torch.tensor([tokenizer.encode(prompt, allowed_special={\"<|endoftext|>\"})], device=device)\n",
    "    tokens = tokens.repeat(num_return_sequences, 1)\n",
    "\n",
    "    sample_rng = torch.Generator(device=device)\n",
    "    sample_rng.manual_seed(1337)\n",
    "\n",
    "    eos_token_id = tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"})[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in tqdm.tqdm(range(max_length - tokens.size(1))):\n",
    "            with torch.amp.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "                logits = model(tokens)\n",
    "                logits = logits[:, -1, :]  # Get logits for the last token\n",
    "\n",
    "                # Apply temperature scaling if temperature > 0\n",
    "                if temperature > 0:\n",
    "                    logits = logits / temperature\n",
    "\n",
    "            probs = F.softmax(logits, dim=-1)  # Compute probabilities\n",
    "\n",
    "            # Top-K sampling: set all probabilities outside the top K to 0\n",
    "            top_k_probs, top_k_indices = torch.topk(probs, top_k, dim=-1)\n",
    "            ix = torch.multinomial(top_k_probs, 1, generator=sample_rng)\n",
    "            next_token = torch.gather(top_k_indices, -1, ix)\n",
    "            tokens = torch.cat((tokens, next_token), dim=1)\n",
    "\n",
    "            # Break if EOS token is generated\n",
    "            if (next_token == eos_token_id).any():\n",
    "                break\n",
    "\n",
    "    generated_sequences = []\n",
    "    for i in range(num_return_sequences):\n",
    "        decoded = tokenizer.decode(tokens[i].tolist())\n",
    "        generated_sequences.append(decoded)\n",
    "\n",
    "    return generated_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating text for prompt: 'The future of artificial intelligence is'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:06<00:00,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: The future of artificial intelligence is also a bit controversial in the political area. The idea of artificial intelligence is actually a part of people who might not have a clear idea of how can we make this technology come to life. People that already have computers can\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"The future of artificial intelligence is\",\n",
    "    # \"In the year 2050, the world will\",\n",
    "    # \"The most important scientific discovery of the 21st century is\",\n",
    "    # \"If I could change one thing about the education system, it would be\",\n",
    "    # \"In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\",\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"\\nGenerating text for prompt: '{prompt}'\\n\")\n",
    "    generated_texts = generate_text(model, tokenizer, prompt, num_return_sequences=1, max_length=50)\n",
    "    for i, text in enumerate(generated_texts):\n",
    "        print(f\"Sample {i + 1}: {text}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "stu = copy.deepcopy(model.layers[0].stu)\n",
    "stu.phi = stu.phi.to(torch.bfloat16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, n_layers, 2):\n",
    "#     stu_layer = copy.deepcopy(model.layers[i].stu)\n",
    "#     stu_layer.phi = stu_layer.phi.to(torch.bfloat16)\n",
    "#     torch.save(stu_layer.state_dict(), f\"./stu_layer_{i}_500m_param.pt\")\n",
    "#     torch.save(stu_layer, f\"./stu_layer_{i}_500m_param_full.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the full STU layer\n",
    "# stu_layer_full = torch.load(\"./stu_layers/stu_layer_0_500m_param_full.pt\")\n",
    "# stu_layer_full.to(device)s\n",
    "\n",
    "# # Prepare some input data\n",
    "# inputs = torch.randn(5, 1024, 768).to(device).to(torch.bfloat16)\n",
    "\n",
    "# # Run the STU layer\n",
    "# outputs = stu_layer_full(inputs)\n",
    "# print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the saved STU layer\n",
    "# stu_larch.load(\"./stu_layer_0_500m_param.pt\"))\n",
    "# stu_layer.to(device)\n",
    "\n",
    "# # Prepare some input data\n",
    "# inputs = torch.randn(5, 1024, 768).to(device).to(torch.bfloat16)\n",
    "\n",
    "# # Run the STU layer\n",
    "# outputs = stu_layer(inputs)\n",
    "# print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LDS' object has no attribute 'phi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m stu \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstu)\n\u001b[1;32m----> 3\u001b[0m stu\u001b[38;5;241m.\u001b[39mphi \u001b[38;5;241m=\u001b[39m \u001b[43mstu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphi\u001b[49m\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mbfloat16)\n",
      "File \u001b[1;32mc:\\Users\\devan\\anaconda3\\envs\\flashstu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1933\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LDS' object has no attribute 'phi'"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "stu = copy.deepcopy(model.layers[0].stu)\n",
    "stu.phi = stu.phi.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.randn(1, 1024, 768).to(device).to(torch.bfloat16)\n",
    "stu(inputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_init(size, lam=5.0):\n",
    "    \"\"\"\n",
    "    Samples from an exponential distribution with rate lam, \n",
    "    then clips at 1, does (1 - clipped_value),\n",
    "    and finally multiplies by ±1 with probability 1/2.\n",
    "    \"\"\"\n",
    "    # 1) Sample uniform [0,1], convert to exponential\n",
    "    u = torch.rand(size)\n",
    "    x = -1.0 / lam * torch.log(1 - u)  # Exponential(λ = lam)\n",
    "\n",
    "    # 2) Clip at 1\n",
    "    x = torch.clamp(x, max=1.0)\n",
    "\n",
    "    # 3) Subtract from 1 (to be near 1 for small x)\n",
    "    x = 1.0 - x  # Now we have distribution mostly near 1 for large lam\n",
    "\n",
    "    # 4) Multiply by ±1 with prob 1/2\n",
    "    sign = torch.sign(torch.randn(size))\n",
    "    return x * sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(exponential_decay_init(\u001b[43mA\u001b[49m\u001b[38;5;241m.\u001b[39mshape, lam \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m), bins \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(exponential_decay_init(A.shape, lam = 15), bins =50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_ar_x_preds(w: torch.Tensor, x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the auto-regressive component of a spectral SSM (PyTorch version),\n",
    "    allowing for a batch dimension in `x`.\n",
    "\n",
    "    Args:\n",
    "        w: A tensor of shape [d_out, d_in, k].\n",
    "        x: A tensor of shape [batch_size, l, d_in].\n",
    "\n",
    "    Returns:\n",
    "        A tensor of shape [batch_size, l, d_out].\n",
    "    \"\"\"\n",
    "    d_out, d_in, k = w.shape\n",
    "    b, l, d_in_x = x.shape\n",
    "    assert d_in == d_in_x, (\n",
    "        f\"Dimension mismatch: w.shape={w.shape}, x.shape={x.shape}\"\n",
    "    )\n",
    "\n",
    "    o = torch.einsum(\"oik,bli->bklo\", w, x)\n",
    "\n",
    "    for i in range(k):\n",
    "        # shape: [b, l, d_out]\n",
    "        o[:, i] = torch.roll(o[:, i], shifts=i, dims=1)\n",
    "\n",
    "    m = torch.triu(torch.ones(k, l, dtype=o.dtype, device=o.device))  # [k, l]\n",
    "    # shape: [k, l, 1] -> then repeat along d_out\n",
    "    m = m.unsqueeze(-1).repeat(1, 1, d_out)  # [k, l, d_out]\n",
    "\n",
    "    ar_x_preds = torch.sum(o * m, dim=1)  # now shape is [b, l, d_out]\n",
    "\n",
    "    return ar_x_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDS(nn.Module):\n",
    "    def __init__(self, state_dim, input_dim, output_dim, kx=5):\n",
    "        super(LDS, self).__init__()\n",
    "        self.state_dim = state_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.kx = kx\n",
    "        self.h0 = nn.Parameter(torch.randn(state_dim))\n",
    "        # init_A = torch.randn(state_dim)\n",
    "        # self.A = nn.Parameter(init_A / torch.max(torch.abs(init_A)))\n",
    "\n",
    "        # self.A = nn.Parameter((torch.rand(state_dim) * 0.2 + 0.8) * torch.sign(torch.randn(state_dim)))\n",
    "        self.A = nn.Parameter(exponential_decay_init([state_dim], lam = 15))\n",
    "        self.B = nn.Parameter(torch.randn(input_dim, state_dim) / input_dim)\n",
    "        self.C = nn.Parameter(torch.randn(state_dim, output_dim) / state_dim)\n",
    "        self.M = nn.Parameter(torch.randn(output_dim, input_dim, kx) / (output_dim))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        device = inputs.device\n",
    "        bsz, seq_len, _ = inputs.shape\n",
    "        h_t = self.h0.expand(bsz, self.state_dim).to(device)\n",
    "        A = self.A.flatten()\n",
    "        all_h_t = []\n",
    "        for t in range(seq_len):\n",
    "            u_t = inputs[:, t, :]\n",
    "            h_t = A * h_t + (u_t @ self.B)\n",
    "            all_h_t.append(h_t.unsqueeze(1))\n",
    "        all_h_t = torch.cat(all_h_t, dim=1)\n",
    "        lds_out = torch.matmul(all_h_t, self.C)\n",
    "\n",
    "        ar = compute_ar_x_preds(self.M, inputs)\n",
    "        return lds_out + ar\n",
    "\n",
    "    def compute_loss(self, inputs, targets):\n",
    "        mse_loss = nn.MSELoss()\n",
    "        outputs = self(inputs)\n",
    "        return mse_loss(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class LDS_LR(nn.Module):\n",
    "    def __init__(self, state_dim, input_dim, output_dim, kx=5, rank = 50):\n",
    "        super(LDS_LR, self).__init__()\n",
    "        self.state_dim = state_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.kx = kx\n",
    "        self.h0 = nn.Parameter(torch.randn(state_dim))\n",
    "        # init_A = torch.randn(state_dim)\n",
    "        # self.A = nn.Parameter(init_A / torch.max(torch.abs(init_A)))\n",
    "\n",
    "        self.A = nn.Parameter(exponential_decay_init([state_dim], lam = 15))\n",
    "        self.B1 = nn.Parameter(torch.randn(input_dim, rank) / (input_dim))\n",
    "        self.B2 = nn.Parameter(torch.randn(rank, state_dim) / (rank))\n",
    "        self.C1 = nn.Parameter(torch.randn(state_dim, rank) / (state_dim))\n",
    "        self.C2 = nn.Parameter(torch.randn(rank, output_dim) / (rank))\n",
    "        self.M = nn.Parameter(torch.randn(output_dim, input_dim, kx) / (output_dim))\n",
    "\n",
    "\n",
    "        # self.M1 = nn.Parameter(torch.randn(rank, input_dim, kx) / math.sqrt(output_dim))\n",
    "        # self.M2 = nn.Parameter(torch.randn(output_dim, rank, kx) / math.sqrt(output_dim))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        device = inputs.devic\n",
    "        bsz, seq_len, _ = inputs.shape\n",
    "        h_t = self.h0.expand(bsz, self.state_dim).to(device)\n",
    "        A = self.A.flatten()\n",
    "        all_h_t = []\n",
    "\n",
    "        lds_in = torch.matmul(inputs, self.B1)\n",
    "        lds_in = torch.matmul(lds_in, self.B2)\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            h_t = A * h_t + lds_in[:, t, :]\n",
    "            all_h_t.append(h_t.unsqueeze(1))\n",
    "        all_h_t = torch.cat(all_h_t, dim=1)\n",
    " \n",
    "        lds_out = torch.matmul(all_h_t, self.C1)\n",
    "        lds_out = torch.matmul(lds_out, self.C2)\n",
    "\n",
    "        ar = compute_ar_x_preds(self.M, inputs)\n",
    "\n",
    "        # ar = compute_ar_x_preds(self.M1, inputs)\n",
    "        # ar = comspute_ar_x_preds(self.M2, ar)\n",
    "        \n",
    "        return lds_out + ar\n",
    "\n",
    "    def compute_loss(self, inputs, targets):\n",
    "        mse_loss = nn.MSELoss()\n",
    "        outputs = self(inputs)\n",
    "        return mse_loss(outputs, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(5, 4096, 768).to(device).to(torch.float)\n",
    "bsz, seq_len, _ = inputs.shape\n",
    "h_t = lds.h0.expand(bsz, lds.state_dim).to(device)\n",
    "A = lds.A.flatten()\n",
    "all_h_t = []\n",
    "\n",
    "lds_in = torch.matmul(inputs, lds.B1)\n",
    "lds_in = torch.matmul(lds_in, lds.B2)\n",
    "\n",
    "for t in range(seq_len):\n",
    "    h_t = A * h_t + lds_in[:, t, :]\n",
    "    all_h_t.append(h_t.unsqueeze(1))\n",
    "all_h_t = torch.cat(all_h_t, dim=1)\n",
    "\n",
    "lds_out = torch.matmul(all_h_t, lds.C1)\n",
    "lds_out = torch.matmul(lds_out, lds.C2)\n",
    "\n",
    "ar = compute_ar_x_preds(lds.M1, inputs)\n",
    "ar = compute_ar_x_preds(lds.M2, ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected mat1 and mat2 to have the same dtype, but got: float != struct c10::BFloat16",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(lds_epochs):\n\u001b[0;32m      9\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m4096\u001b[39m, \u001b[38;5;241m768\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mbfloat16)\n\u001b[1;32m---> 10\u001b[0m     stu_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mstu\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     12\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m lds\u001b[38;5;241m.\u001b[39mcompute_loss(inputs\u001b[38;5;241m.\u001b[39mto(stu_outputs\u001b[38;5;241m.\u001b[39mdtype), stu_outputs)\n",
      "File \u001b[1;32mc:\\Users\\devan\\anaconda3\\envs\\flashstu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\devan\\anaconda3\\envs\\flashstu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\devan\\Downloads\\stu_lm_backup\\inference\\stu.py:54\u001b[0m, in \u001b[0;36mSTU.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_approx:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# Contract inputs and filters over the K and d_in dimensions, then convolve\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     x_proj \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM_inputs\n\u001b[1;32m---> 54\u001b[0m     phi_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mM_filters\u001b[49m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflash_fft:\n\u001b[0;32m     56\u001b[0m         spectral_plus, spectral_minus \u001b[38;5;241m=\u001b[39m flash_convolve(\n\u001b[0;32m     57\u001b[0m             x_proj, phi_proj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflash_fft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_approx\n\u001b[0;32m     58\u001b[0m         )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected mat1 and mat2 to have the same dtype, but got: float != struct c10::BFloat16"
     ]
    }
   ],
   "source": [
    "#remarkably, the approximation gets better and better as state_dim increases from  20 to ~500 (i.e 500 is 8x better than 50)\n",
    "state_dim = 100 #@param\n",
    "lds = LDS(state_dim, 768, 768, kx = 5).to(device)\n",
    "optimizer = torch.optim.Adam(lds.parameters(), lr = 0.002)\n",
    "lds_epochs = 3001\n",
    "lds_loss_values = []\n",
    "\n",
    "for epoch in range(lds_epochs):\n",
    "    inputs = torch.randn(5, 4096, 768).to(device).to(torch.bfloat16)\n",
    "    stu_outputs = stu(inputs).to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = lds.compute_loss(inputs.to(stu_outputs.dtype), stu_outputs)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(lds.parameters(), max_norm=1)\n",
    "    lds_loss_values.append(loss.item())\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        lds.A.data.clamp_(max=1, min = -1)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}') #Epoch 2000, Loss: 0.00030023115687072277 for normal LDS and  state dim  10000\n",
    "        #Epoch 2000, Loss: 0.001 for normal LDS and  state dim  1000\n",
    "        #0.0007 for 2000 epochs on LDS with 5 autoregressive heads\n",
    "\n",
    "        #with improved init we reach 0.00029 in 300 epochs at kx = 5\n",
    "        #with improved init we reach 0.00027 in 300 epochs (range 0.7 - 1) at kx =5\n",
    "        #with improved init we reached 0.00024 in 300 with range (0.8 - 1) at kx = 5\n",
    "        #but worse perf for (0.9 - 1) at kx = 10\n",
    "        #0.00020 with lam = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert lds.A to a numpy array and plot the histogram\n",
    "A_data = lds.A.data.cpu().numpy()\n",
    "plt.hist(A_data, bins=100, alpha=0.75)\n",
    "plt.title('Histogram of lds.A')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2162, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.abs(stu_outputs - stu_outputs.mean())).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lds.state_dict(), \"./lds_layer_new_2cap_0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devan\\AppData\\Local\\Temp\\ipykernel_3020\\743698104.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"./lds_trained/9496_0_10000_0.00002_lds_model_and_optimizer.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New LDS model created and initialized.\n"
     ]
    }
   ],
   "source": [
    "# Load the model and optimizer\n",
    "checkpoint = torch.load(\"./lds_trained/9496_0_10000_0.00002_lds_model_and_optimizer.pt\")\n",
    "del checkpoint['lds_state_dict']['M'] #this param doesn't correspond to current M\n",
    "lds_model = LDS(state_dim=10000, input_dim=768, output_dim=768, kx=0)\n",
    "lds_model.load_state_dict(checkpoint['lds_state_dict'], strict =  False)\n",
    "\n",
    "# Compute Cdiag(A)^iB for i in range(0, 10)\n",
    "C = lds_model.C\n",
    "A = lds_model.A\n",
    "B = lds_model.B\n",
    "\n",
    "\n",
    "\n",
    "M = torch.zeros((768, 768, 10), device=device)\n",
    "low_order_A = A.clone()\n",
    "low_order_A[(low_order_A > 0.7) | (low_order_A < -0.7)] = 0\n",
    "\n",
    "for i in range(10): #encompases low order terms or so\n",
    "    M[:, :, i] = (C.T  @ (B * low_order_A).T)\n",
    "\n",
    "# Create a new LDS with kx = 10 and M initialized to these values\n",
    "new_lds = LDS(state_dim=80000, input_dim=768, output_dim=768, kx=10)\n",
    "new_lds.M.data = M\n",
    "\n",
    "# Set all terms with low magnitude in A to 0\n",
    "threshold = 0.7  # Define a threshold for low magnitude\n",
    "A_new  = A.detach().clone()\n",
    "A_new[torch.abs(A_new) < threshold] = 0\n",
    "new_lds.A.data = A_new\n",
    "\n",
    "new_lds.B.data = B.clone()\n",
    "new_lds.C.data = C.clone()\n",
    "print(\"New LDS model created and initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFG0lEQVR4nO3dfVxUZf7/8fcAAt4NhAojm/eZSmKWrkpZlpKobKtJW5oZGpvlombeVOyqebd5m1ouZbWKtmmWrVpr3qGlVqImWZmad2lYOlgZIJrIzfn94Y/5NoIK48CMp9fz8TiPmutc55zPNYeBt9ecM2MxDMMQAACASfl4ugAAAICKRNgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBficaNmyoAQMGeLoM05sxY4YaN24sX19ftW7d+pL9BgwYoIYNG15xf0ePHpXFYtHChQvdViPwe0PYAa5BCxculMVi0c6dO0tdf9ddd6lly5ZXfZzVq1dr/PjxV72f34v169fr6aef1u23366UlBQ9//zzni7pkp5++mlZLBY9+OCDni4FqHB+ni4AQOXYv3+/fHzK9++b1atXKzk5mcBTRh9++KF8fHw0f/58+fv7e7qcSzIMQ2+99ZYaNmyo//3vfzp9+rRq1qzp6bKACsPMDvA7ERAQoCpVqni6jHI5c+aMp0sol5MnT6pq1apeHXQkadOmTfr++++1YMECFRQUaPny5Z4uCahQhB3gd+Lia3by8/M1YcIENW3aVIGBgapVq5Y6duyo1NRUSReuKUlOTpYkWSwWx1LszJkzGjlypOrVq6eAgAA1a9ZMM2fOlGEYTsf99ddfNWzYMNWuXVs1a9bUn//8Z/3www+yWCxOM0bjx4+XxWLR3r179dBDD+m6665Tx44dJUlfffWVBgwYoMaNGyswMFA2m02PPvqofv75Z6djFe/jwIEDevjhhxUUFKQ6depo7NixMgxDx44dU8+ePWW1WmWz2fTCCy+U6bkrKCjQpEmT1KRJEwUEBKhhw4b6+9//rry8PEcfi8WilJQUnTlzxvFclfc6m6ysLA0YMEBBQUEKDg5WfHy8srKySvSz2+0aOHCgrr/+egUEBKhu3brq2bOnjh49WqbjLF68WBEREbr77rsVHR2txYsXl6tO4FrD21jANSw7O1s//fRTifb8/Pwrbjt+/HhNmTJFf/3rX9WuXTvl5ORo586d+vzzz3XPPffo8ccf1/Hjx5Wamqr//Oc/TtsahqE///nP+uijj5SQkKDWrVtr3bp1Gj16tH744QfNnj3b0XfAgAF655131L9/f3Xo0EGbN29WbGzsJev6y1/+oqZNm+r55593BKfU1FR9++23GjhwoGw2m/bs2aPXXntNe/bs0bZt25xCmCQ9+OCDatGihaZOnaoPPvhAkydPVkhIiF599VV17txZ06ZN0+LFizVq1Cj98Y9/1J133nnZ5+qvf/2rFi1apPvvv18jR47U9u3bNWXKFO3bt08rVqyQJP3nP//Ra6+9ph07dujf//63JOm222674nn47XPas2dPffLJJ3riiSfUokULrVixQvHx8SX6xsXFac+ePRo6dKgaNmyokydPKjU1VRkZGVe86DkvL0///e9/NXLkSElS3759NXDgQNntdtlstjLXC1xTDADXnJSUFEPSZZebbrrJaZsGDRoY8fHxjsc333yzERsbe9njJCYmGqX9mli5cqUhyZg8ebJT+/33329YLBbj0KFDhmEYRnp6uiHJGD58uFO/AQMGGJKM5557ztH23HPPGZKMvn37ljje2bNnS7S99dZbhiRjy5YtJfYxaNAgR1tBQYFx/fXXGxaLxZg6daqj/ZdffjGqVq3q9JyU5osvvjAkGX/961+d2keNGmVIMj788ENHW3x8vFG9evXL7u+3fRs0aOB4XPycTp8+3an2O+64w5BkpKSkOOqWZMyYMaNMx7nYu+++a0gyDh48aBiGYeTk5BiBgYHG7NmzXdofcC3gbSzgGpacnKzU1NQSS6tWra64bXBwsPbs2aODBw+W+7irV6+Wr6+vhg0b5tQ+cuRIGYahNWvWSJLWrl0rSfrb3/7m1G/o0KGX3PcTTzxRoq1q1aqO/z937px++ukndejQQZL0+eefl+j/17/+1fH/vr6+atu2rQzDUEJCgqM9ODhYzZo107fffnvJWqQLY5WkESNGOLUXz4x88MEHl92+rFavXi0/Pz8NHjzYqfaLn6via4I2bdqkX375pdzHWbx4sdq2basbbrhBklSzZk3FxsbyVhZMjbADXMPatWun6OjoEst11113xW0nTpyorKws3XjjjYqMjNTo0aP11Vdflem43333ncLDw0vcwdOiRQvH+uL/+vj4qFGjRk79iv/QlubivpJ06tQpPfnkkwoLC1PVqlVVp04dR7/s7OwS/evXr+/0OCgoSIGBgapdu3aJ9isFhuIxXFyzzWZTcHCwY6xX67vvvlPdunVVo0YNp/ZmzZo5PQ4ICNC0adO0Zs0ahYWF6c4779T06dNlt9uveIysrCytXr1anTp10qFDhxzL7bffrp07d+rAgQNuGQvgbQg7wO/UnXfeqcOHD2vBggVq2bKl/v3vf+vWW291XG/iKb+dxSn2wAMP6PXXX9cTTzyh5cuXa/369Y5Zo6KiohL9fX19y9QmqcQF1Zdy8XVBnjR8+HAdOHBAU6ZMUWBgoMaOHasWLVpo165dl91u2bJlysvL0wsvvKCmTZs6luJZK2Z3YFaEHeB3LCQkRAMHDtRbb72lY8eOqVWrVk53SF3qD3yDBg10/PhxnT592qn9m2++cawv/m9RUZGOHDni1O/QoUNlrvGXX37Rxo0b9eyzz2rChAm67777dM8996hx48Zl3sfVKB7DxW/3ZWZmKisryzFWdxznxIkTys3NdWrfv39/qf2bNGmikSNHav369fr66691/vz5K95dtnjxYrVs2VLLli0rsURHR2vJkiVuGQvgbQg7wO/Uxbdt16hRQzfccIPT7dTVq1eXpBK3P/fo0UOFhYX617/+5dQ+e/ZsWSwWde/eXZIUExMjSXr55Zed+s2dO7fMdRbPyFw8AzNnzpwy7+Nq9OjRo9TjzZo1S5Iue2dZeY9TUFCgV155xdFWWFhY4rk6e/aszp0759TWpEkT1axZ0+ncnThxQt98843jzrxjx45py5YteuCBB3T//feXWAYOHKhDhw5p+/btbhkP4E249Rz4nYqIiNBdd92lNm3aKCQkRDt37tS7776rIUOGOPq0adNGkjRs2DDFxMTI19dXffr00b333qu7775b//jHP3T06FHdfPPNWr9+vd577z0NHz5cTZo0cWwfFxenOXPm6Oeff3bcel58bUhZ3hqyWq2O61Ly8/P1hz/8QevXry8xW1RRbr75ZsXHx+u1115TVlaWOnXqpB07dmjRokXq1auX7r77brcc595779Xtt9+uZ599VkePHlVERISWL19e4pqkAwcOqEuXLnrggQcUEREhPz8/rVixQpmZmerTp4+jX1JSkhYtWqQjR46oYcOGWrJkieMjA0rTo0cP+fn5afHixWrfvr1bxgR4C8IO8Ds1bNgwvf/++1q/fr3y8vLUoEEDTZ48WaNHj3b06d27t4YOHaqlS5fqzTfflGEY6tOnj3x8fPT+++9r3Lhxevvtt5WSkqKGDRtqxowZjruUir3xxhuy2Wx66623tGLFCkVHR+vtt99Ws2bNFBgYWKZalyxZoqFDhyo5OVmGYahr165as2aNwsPD3fqcXMq///1vNW7cWAsXLtSKFStks9mUlJSk5557zm3HKH5Ohw8frjfffFMWi0V//vOf9cILL+iWW25x9KtXr5769u2rjRs36j//+Y/8/PzUvHlzvfPOO4qLi7vk/hcvXqz69evr5ptvLnV9cHCwOnbsqLfffluzZs2Snx9/HmAeFqOsV+cBgJt88cUXuuWWW/Tmm2+qX79+ni4HgMlxzQ6ACvXrr7+WaJszZ458fHyu+MnFAOAOzFMCqFDTp09Xenq67r77bvn5+WnNmjVas2aNBg0apHr16nm6PAC/A7yNBaBCpaamasKECdq7d69yc3NVv3599e/fX//4xz+4LgRApSDsAAAAU+OaHQAAYGqEHQAAYGq8Ya4L361z/Phx1axZ06u+/wYAAFyaYRg6ffq0wsPD5eNz6fkbwo6k48ePc1cIAADXqGPHjun666+/5HrCjqSaNWtKuvBkWa1WD1cDAADKIicnR/Xq1XP8Hb8Uwo7+7/t5rFYrYQcAgGvMlS5B4QJlAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgan6eLuD3qM9raU6Plw6K8lAlAACYHzM7AADA1DwadgoLCzV27Fg1atRIVatWVZMmTTRp0iQZhuHoYxiGxo0bp7p166pq1aqKjo7WwYMHnfZz6tQp9evXT1arVcHBwUpISFBubm5lDwcAAHghj4adadOm6ZVXXtG//vUv7du3T9OmTdP06dM1d+5cR5/p06frpZde0rx587R9+3ZVr15dMTExOnfunKNPv379tGfPHqWmpmrVqlXasmWLBg0a5IkhAQAAL+PRa3a2bt2qnj17KjY2VpLUsGFDvfXWW9qxY4ekC7M6c+bM0ZgxY9SzZ09J0htvvKGwsDCtXLlSffr00b59+7R27Vp99tlnatu2rSRp7ty56tGjh2bOnKnw8HDPDA4AAHgFj87s3Hbbbdq4caMOHDggSfryyy/1ySefqHv37pKkI0eOyG63Kzo62rFNUFCQ2rdvr7S0Cxf5pqWlKTg42BF0JCk6Olo+Pj7avn17qcfNy8tTTk6O0wIAAMzJozM7zz77rHJyctS8eXP5+vqqsLBQ//znP9WvXz9Jkt1ulySFhYU5bRcWFuZYZ7fbFRoa6rTez89PISEhjj4XmzJliiZMmODu4QAAAC/k0Zmdd955R4sXL9aSJUv0+eefa9GiRZo5c6YWLVpUocdNSkpSdna2Yzl27FiFHg8AAHiOR2d2Ro8erWeffVZ9+vSRJEVGRuq7777TlClTFB8fL5vNJknKzMxU3bp1HdtlZmaqdevWkiSbzaaTJ0867begoECnTp1ybH+xgIAABQQEVMCIAACAt/HozM7Zs2fl4+Ncgq+vr4qKiiRJjRo1ks1m08aNGx3rc3JytH37dkVFXfggvqioKGVlZSk9Pd3R58MPP1RRUZHat29fCaMAAADezKMzO/fee6/++c9/qn79+rrpppu0a9cuzZo1S48++qgkyWKxaPjw4Zo8ebKaNm2qRo0aaezYsQoPD1evXr0kSS1atFC3bt302GOPad68ecrPz9eQIUPUp08f7sQCAACeDTtz587V2LFj9be//U0nT55UeHi4Hn/8cY0bN87R5+mnn9aZM2c0aNAgZWVlqWPHjlq7dq0CAwMdfRYvXqwhQ4aoS5cu8vHxUVxcnF566SVPDAkAAHgZi/Hbjyv+ncrJyVFQUJCys7NltVor/Hh8NxYAAFevrH+/+W4sAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgan6eLgBSn9fSSrQtHRTlgUoAADAfZnYAAICpEXYAAICp8TYWAABw2bVwKQYzOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQ8GnYaNmwoi8VSYklMTJQknTt3TomJiapVq5Zq1KihuLg4ZWZmOu0jIyNDsbGxqlatmkJDQzV69GgVFBR4YjgAAMALeTTsfPbZZzpx4oRjSU1NlST95S9/kSQ99dRT+t///qdly5Zp8+bNOn78uHr37u3YvrCwULGxsTp//ry2bt2qRYsWaeHChRo3bpxHxgMAALyPR78ItE6dOk6Pp06dqiZNmqhTp07Kzs7W/PnztWTJEnXu3FmSlJKSohYtWmjbtm3q0KGD1q9fr71792rDhg0KCwtT69atNWnSJD3zzDMaP368/P39PTEsAABMq7Qv/vR2XnPNzvnz5/Xmm2/q0UcflcViUXp6uvLz8xUdHe3o07x5c9WvX19paRee6LS0NEVGRiosLMzRJyYmRjk5OdqzZ88lj5WXl6ecnBynBQAAmJPXhJ2VK1cqKytLAwYMkCTZ7Xb5+/srODjYqV9YWJjsdrujz2+DTvH64nWXMmXKFAUFBTmWevXquW8gAADAq3hN2Jk/f766d++u8PDwCj9WUlKSsrOzHcuxY8cq/JgAAMAzPHrNTrHvvvtOGzZs0PLlyx1tNptN58+fV1ZWltPsTmZmpmw2m6PPjh07nPZVfLdWcZ/SBAQEKCAgwI0jAAAA3sorZnZSUlIUGhqq2NhYR1ubNm1UpUoVbdy40dG2f/9+ZWRkKCoqSpIUFRWl3bt36+TJk44+qampslqtioiIqLwBAAAAr+XxmZ2ioiKlpKQoPj5efn7/V05QUJASEhI0YsQIhYSEyGq1aujQoYqKilKHDh0kSV27dlVERIT69++v6dOny263a8yYMUpMTGTmBgAASPKCsLNhwwZlZGTo0UcfLbFu9uzZ8vHxUVxcnPLy8hQTE6OXX37Zsd7X11erVq3S4MGDFRUVperVqys+Pl4TJ06szCEAAAAvZjEMw/B0EZ6Wk5OjoKAgZWdny2q1VvjxyvIZBUsHRVV4HQAAXI6rn6lTWX/Dyvr32yuu2QEAAKgohB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqHv9uLJTu4o/o5usjAABwDTM7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Dwedn744Qc9/PDDqlWrlqpWrarIyEjt3LnTsd4wDI0bN05169ZV1apVFR0drYMHDzrt49SpU+rXr5+sVquCg4OVkJCg3Nzcyh4KAADwQh4NO7/88otuv/12ValSRWvWrNHevXv1wgsv6LrrrnP0mT59ul566SXNmzdP27dvV/Xq1RUTE6Nz5845+vTr10979uxRamqqVq1apS1btmjQoEGeGBIAAPAyfp48+LRp01SvXj2lpKQ42ho1auT4f8MwNGfOHI0ZM0Y9e/aUJL3xxhsKCwvTypUr1adPH+3bt09r167VZ599prZt20qS5s6dqx49emjmzJkKDw+v3EEBAACv4tGZnffff19t27bVX/7yF4WGhuqWW27R66+/7lh/5MgR2e12RUdHO9qCgoLUvn17paWlSZLS0tIUHBzsCDqSFB0dLR8fH23fvr3yBgMAALySR8POt99+q1deeUVNmzbVunXrNHjwYA0bNkyLFi2SJNntdklSWFiY03ZhYWGOdXa7XaGhoU7r/fz8FBIS4uhzsby8POXk5DgtAADAnDz6NlZRUZHatm2r559/XpJ0yy236Ouvv9a8efMUHx9fYcedMmWKJkyYUGH7BwAA3sOjMzt169ZVRESEU1uLFi2UkZEhSbLZbJKkzMxMpz6ZmZmOdTabTSdPnnRaX1BQoFOnTjn6XCwpKUnZ2dmO5dixY24ZDwAA8D4eDTu333679u/f79R24MABNWjQQNKFi5VtNps2btzoWJ+Tk6Pt27crKipKkhQVFaWsrCylp6c7+nz44YcqKipS+/btSz1uQECArFar0wIAAMzJo29jPfXUU7rtttv0/PPP64EHHtCOHTv02muv6bXXXpMkWSwWDR8+XJMnT1bTpk3VqFEjjR07VuHh4erVq5ekCzNB3bp102OPPaZ58+YpPz9fQ4YMUZ8+fbgTCwAAeDbs/PGPf9SKFSuUlJSkiRMnqlGjRpozZ4769evn6PP000/rzJkzGjRokLKystSxY0etXbtWgYGBjj6LFy/WkCFD1KVLF/n4+CguLk4vvfSSJ4YEAAC8jMUwDMPTRXhaTk6OgoKClJ2dXSlvafV5La3c2ywdFFUBlQAAcGmu/L2SKu9vVln/fnv86yIAAAAqEmEHAACYmkev2fk9cHUKEAAAuAczOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNT4UEEAAOBWF3+grqe/35GZHQAAYGqEHQAAYGqEHQAAYGqEHQAAYGqEHQAAYGqEHQAAYGqEHQAAYGqEHQAAYGqEHQAAYGqEHQAAYGqEHQAAYGqEHQAAYGqEHQAAYGqEHQAAYGqEHQAAYGp+ni4AAAB4hz6vpXm6hArBzA4AADA1wg4AADA1wg4AADA1wg4AADA1j4ad8ePHy2KxOC3Nmzd3rD937pwSExNVq1Yt1ahRQ3FxccrMzHTaR0ZGhmJjY1WtWjWFhoZq9OjRKigoqOyhAAAAL+Xxu7FuuukmbdiwwfHYz+//Snrqqaf0wQcfaNmyZQoKCtKQIUPUu3dvffrpp5KkwsJCxcbGymazaevWrTpx4oQeeeQRValSRc8//3yljwUAAHgfj4cdPz8/2Wy2Eu3Z2dmaP3++lixZos6dO0uSUlJS1KJFC23btk0dOnTQ+vXrtXfvXm3YsEFhYWFq3bq1Jk2apGeeeUbjx4+Xv79/ZQ8HAAB4GZfexvr222/dVsDBgwcVHh6uxo0bq1+/fsrIyJAkpaenKz8/X9HR0Y6+zZs3V/369ZWWduFzANLS0hQZGamwsDBHn5iYGOXk5GjPnj1uqxEAAFy7XAo7N9xwg+6++269+eabOnfunMsHb9++vRYuXKi1a9fqlVde0ZEjR3THHXfo9OnTstvt8vf3V3BwsNM2YWFhstvtkiS73e4UdIrXF6+7lLy8POXk5DgtAADAnFwKO59//rlatWqlESNGyGaz6fHHH9eOHTvKvZ/u3bvrL3/5i1q1aqWYmBitXr1aWVlZeuedd1wpq8ymTJmioKAgx1KvXr0KPR4AAPAcl8JO69at9eKLL+r48eNasGCBTpw4oY4dO6ply5aaNWuWfvzxR5eKCQ4O1o033qhDhw7JZrPp/PnzysrKcuqTmZnpuMbHZrOVuDur+HFp1wEVS0pKUnZ2tmM5duyYS/UCAADvd1W3nvv5+al3795atmyZpk2bpkOHDmnUqFGqV6+eHnnkEZ04caJc+8vNzdXhw4dVt25dtWnTRlWqVNHGjRsd6/fv36+MjAxFRUVJkqKiorR7926dPHnS0Sc1NVVWq1URERGXPE5AQICsVqvTAgAAzOmqws7OnTv1t7/9TXXr1tWsWbM0atQoHT58WKmpqTp+/Lh69ux52e1HjRqlzZs36+jRo9q6davuu+8++fr6qm/fvgoKClJCQoJGjBihjz76SOnp6Ro4cKCioqLUoUMHSVLXrl0VERGh/v3768svv9S6des0ZswYJSYmKiAg4GqGBgAATMKlW89nzZqllJQU7d+/Xz169NAbb7yhHj16yMfnQnZq1KiRFi5cqIYNG152P99//7369u2rn3/+WXXq1FHHjh21bds21alTR5I0e/Zs+fj4KC4uTnl5eYqJidHLL7/s2N7X11erVq3S4MGDFRUVperVqys+Pl4TJ050ZVgAAMCEXAo7r7zyih599FENGDBAdevWLbVPaGio5s+ff9n9LF269LLrAwMDlZycrOTk5Ev2adCggVavXn3logEAwO+SS2Hn4MGDV+zj7++v+Ph4V3aPUvR5La1E29JBUR6oBACAa4tL1+ykpKRo2bJlJdqXLVumRYsWXXVRAAAA7uJS2JkyZYpq165doj00NJTvpAIAAF7FpbCTkZGhRo0alWhv0KCB4+seAAAAvIFLYSc0NFRfffVVifYvv/xStWrVuuqiAAAA3MWlsNO3b18NGzZMH330kQoLC1VYWKgPP/xQTz75pPr06ePuGgEAAFzm0t1YkyZN0tGjR9WlSxf5+V3YRVFRkR555BGu2QEAAF7FpbDj7++vt99+W5MmTdKXX36pqlWrKjIyUg0aNHB3fQAAAFfFpbBT7MYbb9SNN97orloAAADczqWwU1hYqIULF2rjxo06efKkioqKnNZ/+OGHbikOAADgarkUdp588kktXLhQsbGxatmypSwWi7vrAgAAcAuXws7SpUv1zjvvqEePHu6uBwAAwK1cuvXc399fN9xwg7trAQAAcDuXws7IkSP14osvyjAMd9cDAADgVi69jfXJJ5/oo48+0po1a3TTTTepSpUqTuuXL1/uluIAAACulkthJzg4WPfdd5+7awEAAHA7l8JOSkqKu+sAAACoEC5dsyNJBQUF2rBhg1599VWdPn1aknT8+HHl5ua6rTgAAICr5dLMznfffadu3bopIyNDeXl5uueee1SzZk1NmzZNeXl5mjdvnrvrBAAAcIlLMztPPvmk2rZtq19++UVVq1Z1tN93333auHGj24oDAAC4Wi7N7Hz88cfaunWr/P39ndobNmyoH374wS2FAQAAuINLMztFRUUqLCws0f7999+rZs2aV10UAACAu7gUdrp27ao5c+Y4HlssFuXm5uq5557jKyQAAIBXceltrBdeeEExMTGKiIjQuXPn9NBDD+ngwYOqXbu23nrrLXfXCAAA4DKXws7111+vL7/8UkuXLtVXX32l3NxcJSQkqF+/fk4XLAMAAO/U57U0T5dQaVwKO5Lk5+enhx9+2J21AAAAuJ1LYeeNN9647PpHHnnEpWIAAADczaWw8+STTzo9zs/P19mzZ+Xv769q1aoRdgAAgNdw6W6sX375xWnJzc3V/v371bFjRy5QBgAAXsXl78a6WNOmTTV16tQSsz4AAACe5LawI124aPn48ePu3CUAAMBVcemanffff9/psWEYOnHihP71r3/p9ttvd0thAAAA7uBS2OnVq5fTY4vFojp16qhz58564YUX3FEXAACAW7j83Vi/XQoLC2W327VkyRLVrVvXpUKmTp0qi8Wi4cOHO9rOnTunxMRE1apVSzVq1FBcXJwyMzOdtsvIyFBsbKyqVaum0NBQjR49WgUFBS7VAAAAzMflDxV0p88++0yvvvqqWrVq5dT+1FNP6YMPPtCyZcsUFBSkIUOGqHfv3vr0008lSYWFhYqNjZXNZtPWrVt14sQJPfLII6pSpYqef/55TwylUl386ZdLB0V5qBIAALyXS2FnxIgRZe47a9asy67Pzc1Vv3799Prrr2vy5MmO9uzsbM2fP19LlixR586dJUkpKSlq0aKFtm3bpg4dOmj9+vXau3evNmzYoLCwMLVu3VqTJk3SM888o/Hjx8vf39+V4QEAABNxKezs2rVLu3btUn5+vpo1ayZJOnDggHx9fXXrrbc6+lkslivuKzExUbGxsYqOjnYKO+np6crPz1d0dLSjrXnz5qpfv77S0tLUoUMHpaWlKTIyUmFhYY4+MTExGjx4sPbs2aNbbrml1GPm5eUpLy/P8TgnJ6fsgwcAANcUl8LOvffeq5o1a2rRokW67rrrJF34oMGBAwfqjjvu0MiRI8u0n6VLl+rzzz/XZ599VmKd3W6Xv7+/goODndrDwsJkt9sdfX4bdIrXF6+7lClTpmjChAllqhEAAFzbXLpA+YUXXtCUKVMcQUeSrrvuOk2ePLnMd2MdO3ZMTz75pBYvXqzAwEBXynBZUlKSsrOzHcuxY8cq9fgAAKDyuBR2cnJy9OOPP5Zo//HHH3X69Oky7SM9PV0nT57UrbfeKj8/P/n5+Wnz5s166aWX5Ofnp7CwMJ0/f15ZWVlO22VmZspms0mSbDZbibuzih8X9ylNQECArFar0wIAAMzJpbBz3333aeDAgVq+fLm+//57ff/99/rvf/+rhIQE9e7du0z76NKli3bv3q0vvvjCsbRt21b9+vVz/H+VKlW0ceNGxzb79+9XRkaGoqIu3HUUFRWl3bt36+TJk44+qampslqtioiIcGVoAADAZFy6ZmfevHkaNWqUHnroIeXn51/YkZ+fEhISNGPGjDLto2bNmmrZsqVTW/Xq1VWrVi1He0JCgkaMGKGQkBBZrVYNHTpUUVFR6tChgySpa9euioiIUP/+/TV9+nTZ7XaNGTNGiYmJCggIcGVoAADAZFwKO9WqVdPLL7+sGTNm6PDhw5KkJk2aqHr16m4tbvbs2fLx8VFcXJzy8vIUExOjl19+2bHe19dXq1at0uDBgxUVFaXq1asrPj5eEydOdGsdAADg2nVVHyp44sQJnThxQnfeeaeqVq0qwzDKdLv5pWzatMnpcWBgoJKTk5WcnHzJbRo0aKDVq1e7fEwAAGBuLl2z8/PPP6tLly668cYb1aNHD504cULShbedynrbOQAAQGVwKew89dRTqlKlijIyMlStWjVH+4MPPqi1a9e6rTgAAICr5dLbWOvXr9e6det0/fXXO7U3bdpU3333nVsKAwAAcAeXZnbOnDnjNKNT7NSpU9wFBQAAvIpLYeeOO+7QG2+84XhssVhUVFSk6dOn6+6773ZbcQAAAFfLpbexpk+fri5dumjnzp06f/68nn76ae3Zs0enTp3Sp59+6u4aAQAAXObSzE7Lli114MABdezYUT179tSZM2fUu3dv7dq1S02aNHF3jQAAAC4r98xOfn6+unXrpnnz5ukf//hHRdQEAADgNuWe2alSpYq++uqriqgFAADA7Vx6G+vhhx/W/Pnz3V0LAACA27l0gXJBQYEWLFigDRs2qE2bNiW+E2vWrFluKQ4AAOBqlSvsfPvtt2rYsKG+/vpr3XrrrZKkAwcOOPW5mu/GAgAAcLdyhZ2mTZvqxIkT+uijjyRd+HqIl156SWFhYRVSHAAAwNUq1zU7hmE4PV6zZo3OnDnj1oIAAADcyaULlItdHH4AAAC8TbnCjsViKXFNDtfoAAAAb1aua3YMw9CAAQMcX/Z57tw5PfHEEyXuxlq+fLn7KgQAALgK5Qo78fHxTo8ffvhhtxYDAADgbuUKOykpKRVVBwAAQIW4qguUAQAAvB1hBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmJpHw84rr7yiVq1ayWq1ymq1KioqSmvWrHGsP3funBITE1WrVi3VqFFDcXFxyszMdNpHRkaGYmNjVa1aNYWGhmr06NEqKCio7KEAAAAv5dGwc/3112vq1KlKT0/Xzp071blzZ/Xs2VN79uyRJD311FP63//+p2XLlmnz5s06fvy4evfu7di+sLBQsbGxOn/+vLZu3apFixZp4cKFGjdunKeGBAAAvIzFMAzD00X8VkhIiGbMmKH7779fderU0ZIlS3T//fdLkr755hu1aNFCaWlp6tChg9asWaM//elPOn78uMLCwiRJ8+bN0zPPPKMff/xR/v7+ZTpmTk6OgoKClJ2dLavV6tbx9Hktza37K6+lg6I8enwAgHeqzL9PFfW3qKx/v73mmp3CwkItXbpUZ86cUVRUlNLT05Wfn6/o6GhHn+bNm6t+/fpKS7twgtLS0hQZGekIOpIUExOjnJwcx+xQafLy8pSTk+O0AAAAc/J42Nm9e7dq1KihgIAAPfHEE1qxYoUiIiJkt9vl7++v4OBgp/5hYWGy2+2SJLvd7hR0itcXr7uUKVOmKCgoyLHUq1fPvYMCAABew8/TBTRr1kxffPGFsrOz9e677yo+Pl6bN2+u0GMmJSVpxIgRjsc5OTkEHgCAqXn6sgpP8njY8ff31w033CBJatOmjT777DO9+OKLevDBB3X+/HllZWU5ze5kZmbKZrNJkmw2m3bs2OG0v+K7tYr7lCYgIEABAQFuHgkAAPBGHn8b62JFRUXKy8tTmzZtVKVKFW3cuNGxbv/+/crIyFBU1IULnaKiorR7926dPHnS0Sc1NVVWq1URERGVXjsAAPA+Hp3ZSUpKUvfu3VW/fn2dPn1aS5Ys0aZNm7Ru3ToFBQUpISFBI0aMUEhIiKxWq4YOHaqoqCh16NBBktS1a1dFRESof//+mj59uux2u8aMGaPExERmbgAAgCQPh52TJ0/qkUce0YkTJxQUFKRWrVpp3bp1uueeeyRJs2fPlo+Pj+Li4pSXl6eYmBi9/PLLju19fX21atUqDR48WFFRUapevbri4+M1ceJETw0JAAB4GY+Gnfnz5192fWBgoJKTk5WcnHzJPg0aNNDq1avdXRoAADAJr7tmBwAAwJ0IOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNT8PF0AKlaf19KcHi8dFOWhSgAA8AxmdgAAgKkxswMAgMlcPKv/e8fMDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDWPhp0pU6boj3/8o2rWrKnQ0FD16tVL+/fvd+pz7tw5JSYmqlatWqpRo4bi4uKUmZnp1CcjI0OxsbGqVq2aQkNDNXr0aBUUFFTmUAAAgJfyaNjZvHmzEhMTtW3bNqWmpio/P19du3bVmTNnHH2eeuop/e9//9OyZcu0efNmHT9+XL1793asLywsVGxsrM6fP6+tW7dq0aJFWrhwocaNG+eJIQEAAC/j0VvP165d6/R44cKFCg0NVXp6uu68805lZ2dr/vz5WrJkiTp37ixJSklJUYsWLbRt2zZ16NBB69ev1969e7VhwwaFhYWpdevWmjRpkp555hmNHz9e/v7+nhgaAADwEl51zU52drYkKSQkRJKUnp6u/Px8RUdHO/o0b95c9evXV1rahc8QSEtLU2RkpMLCwhx9YmJilJOToz179pR6nLy8POXk5DgtAADAnLwm7BQVFWn48OG6/fbb1bJlS0mS3W6Xv7+/goODnfqGhYXJbrc7+vw26BSvL15XmilTpigoKMix1KtXz82jAQAA3sJrwk5iYqK+/vprLV26tMKPlZSUpOzsbMdy7NixCj8mAADwDK/4uoghQ4Zo1apV2rJli66//npHu81m0/nz55WVleU0u5OZmSmbzebos2PHDqf9Fd+tVdznYgEBAQoICHDzKAAAgDfy6MyOYRgaMmSIVqxYoQ8//FCNGjVyWt+mTRtVqVJFGzdudLTt379fGRkZioq68O3dUVFR2r17t06ePOnok5qaKqvVqoiIiMoZCAAA8FoendlJTEzUkiVL9N5776lmzZqOa2yCgoJUtWpVBQUFKSEhQSNGjFBISIisVquGDh2qqKgodejQQZLUtWtXRUREqH///po+fbrsdrvGjBmjxMREZm8AAIBnw84rr7wiSbrrrruc2lNSUjRgwABJ0uzZs+Xj46O4uDjl5eUpJiZGL7/8sqOvr6+vVq1apcGDBysqKkrVq1dXfHy8Jk6cWFnDAAAAXsyjYccwjCv2CQwMVHJyspKTky/Zp0GDBlq9erU7SwMAACbhNXdjAQAAVASvuBsLlafPa2kl2pYOivJAJQAAVA5mdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKlx6zkAANe40j5WBP+HmR0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqfBEoAADXEL70s/yY2QEAAKZG2AEAAKbG21goMSW6dFCUhyoBAMD9mNkBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmRtgBAACmxq3nKKG0T+fkdnQAwLXKozM7W7Zs0b333qvw8HBZLBatXLnSab1hGBo3bpzq1q2rqlWrKjo6WgcPHnTqc+rUKfXr109Wq1XBwcFKSEhQbm5uJY4CAAB4M4+GnTNnzujmm29WcnJyqeunT5+ul156SfPmzdP27dtVvXp1xcTE6Ny5c44+/fr10549e5SamqpVq1Zpy5YtGjRoUGUNAQAAeDmPvo3VvXt3de/evdR1hmFozpw5GjNmjHr27ClJeuONNxQWFqaVK1eqT58+2rdvn9auXavPPvtMbdu2lSTNnTtXPXr00MyZMxUeHl5pYwEAAN7Jay9QPnLkiOx2u6Kjox1tQUFBat++vdLSLlxTkpaWpuDgYEfQkaTo6Gj5+Pho+/btlV4zAADwPl57gbLdbpckhYWFObWHhYU51tntdoWGhjqt9/PzU0hIiKNPafLy8pSXl+d4nJOT466yAQCAl/HamZ2KNGXKFAUFBTmWevXqebokAABQQbw27NhsNklSZmamU3tmZqZjnc1m08mTJ53WFxQU6NSpU44+pUlKSlJ2drZjOXbsmJurBwAA3sJrw06jRo1ks9m0ceNGR1tOTo62b9+uqKgLn/kSFRWlrKwspaenO/p8+OGHKioqUvv27S+574CAAFmtVqcFAACYk0ev2cnNzdWhQ4ccj48cOaIvvvhCISEhql+/voYPH67JkyeradOmatSokcaOHavw8HD16tVLktSiRQt169ZNjz32mObNm6f8/HwNGTJEffr04U4sAAAgycNhZ+fOnbr77rsdj0eMGCFJio+P18KFC/X000/rzJkzGjRokLKystSxY0etXbtWgYGBjm0WL16sIUOGqEuXLvLx8VFcXJxeeumlSh8LAADwTh4NO3fddZcMw7jkeovFookTJ2rixImX7BMSEqIlS5ZURHkAAMAEvPbWcwAAUPr3FaJ8vPYCZQAAAHcg7AAAAFPjbSyUycXTqEsHRXmoEgAAyoeZHQAAYGqEHQAAYGqEHQAAYGqEHQAAYGqEHQAAYGqEHQAAYGqEHQAAYGp8zg7chs/iAYCrw1dDVAxmdgAAgKkxswOX8K8PACgffm96DjM7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1LgbCxWmtDsP+OwdAL8H3HnlXZjZAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApsbdWKhUfDM6AKCyMbMDAABMjZkdAADKgc/QufYQduB1eKsLAOBOhB14PT6JGQBwNQg78CimgwFUFGaJUYwLlAEAgKmZZmYnOTlZM2bMkN1u180336y5c+eqXbt2ni4LFaQs/2Jz5V91rs408S9GwPuV5S1xZpvNyRRh5+2339aIESM0b948tW/fXnPmzFFMTIz279+v0NBQT5eHSlCWX1AV+UuM6XKgbK8xd702CCUoD1OEnVmzZumxxx7TwIEDJUnz5s3TBx98oAULFujZZ5/1cHX4PXLXvyAJTfBW7gobnn4dEJp+H675sHP+/Hmlp6crKSnJ0ebj46Po6GilpfFDDO/hyi9V7kSDt/BkKCCQ4Gpd82Hnp59+UmFhocLCwpzaw8LC9M0335S6TV5envLy8hyPs7OzJUk5OTlury//1zNu3yd+3yri5xT4rYEpOyps33EvbqiwfcN7VdTvreL9GoZx2X7XfNhxxZQpUzRhwoQS7fXq1fNANUD5LB/u6QoAoHwq+vfW6dOnFRQUdMn113zYqV27tnx9fZWZmenUnpmZKZvNVuo2SUlJGjFihONxUVGRTp06pVq1aslisbittpycHNWrV0/Hjh2T1Wp12369hdnHJ5l/jGYfn2T+MTK+a5/Zx1iR4zMMQ6dPn1Z4ePhl+13zYcff319t2rTRxo0b1atXL0kXwsvGjRs1ZMiQUrcJCAhQQECAU1twcHCF1Wi1Wk35A1zM7OOTzD9Gs49PMv8YGd+1z+xjrKjxXW5Gp9g1H3YkacSIEYqPj1fbtm3Vrl07zZkzR2fOnHHcnQUAAH6/TBF2HnzwQf34448aN26c7Ha7WrdurbVr15a4aBkAAPz+mCLsSNKQIUMu+baVpwQEBOi5554r8ZaZWZh9fJL5x2j28UnmHyPju/aZfYzeMD6LcaX7tQAAAK5hfBEoAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcLOVfjnP/+p2267TdWqVSvzhxIahqFx48apbt26qlq1qqKjo3Xw4EGnPqdOnVK/fv1ktVoVHByshIQE5ebmVsAIrqy8tRw9elQWi6XUZdmyZY5+pa1funRpZQzJiSvP9V133VWi9ieeeMKpT0ZGhmJjY1WtWjWFhoZq9OjRKigoqMihXFJ5x3jq1CkNHTpUzZo1U9WqVVW/fn0NGzbM8R1yxTx1DpOTk9WwYUMFBgaqffv22rHj8t/jtGzZMjVv3lyBgYGKjIzU6tWrndaX5TVZ2cozxtdff1133HGHrrvuOl133XWKjo4u0X/AgAElzlW3bt0qehiXVJ7xLVy4sETtgYGBTn287RyWZ3yl/T6xWCyKjY119PGm87dlyxbde++9Cg8Pl8Vi0cqVK6+4zaZNm3TrrbcqICBAN9xwgxYuXFiiT3lf1+VmwGXjxo0zZs2aZYwYMcIICgoq0zZTp041goKCjJUrVxpffvml8ec//9lo1KiR8euvvzr6dOvWzbj55puNbdu2GR9//LFxww03GH379q2gUVxeeWspKCgwTpw44bRMmDDBqFGjhnH69GlHP0lGSkqKU7/fPgeVxZXnulOnTsZjjz3mVHt2drZjfUFBgdGyZUsjOjra2LVrl7F69Wqjdu3aRlJSUkUPp1TlHePu3buN3r17G++//75x6NAhY+PGjUbTpk2NuLg4p36eOIdLly41/P39jQULFhh79uwxHnvsMSM4ONjIzMwstf+nn35q+Pr6GtOnTzf27t1rjBkzxqhSpYqxe/duR5+yvCYrU3nH+NBDDxnJycnGrl27jH379hkDBgwwgoKCjO+//97RJz4+3ujWrZvTuTp16lRlDclJeceXkpJiWK1Wp9rtdrtTH286h+Ud388//+w0tq+//trw9fU1UlJSHH286fytXr3a+Mc//mEsX77ckGSsWLHisv2//fZbo1q1asaIESOMvXv3GnPnzjV8fX2NtWvXOvqU9zlzBWHHDVJSUsoUdoqKigybzWbMmDHD0ZaVlWUEBAQYb731lmEYhrF3715DkvHZZ585+qxZs8awWCzGDz/84PbaL8ddtbRu3dp49NFHndrK8iKpaK6Or1OnTsaTTz55yfWrV682fHx8nH4hv/LKK4bVajXy8vLcUntZuescvvPOO4a/v7+Rn5/vaPPEOWzXrp2RmJjoeFxYWGiEh4cbU6ZMKbX/Aw88YMTGxjq1tW/f3nj88ccNwyjba7KylXeMFysoKDBq1qxpLFq0yNEWHx9v9OzZ092luqS847vS71dvO4dXe/5mz55t1KxZ08jNzXW0edP5+62y/A54+umnjZtuusmp7cEHHzRiYmIcj6/2OSsL3saqREeOHJHdbld0dLSjLSgoSO3bt1daWpokKS0tTcHBwWrbtq2jT3R0tHx8fLR9+/ZKrdcdtaSnp+uLL75QQkJCiXWJiYmqXbu22rVrpwULFsio5I98uprxLV68WLVr11bLli2VlJSks2fPOu03MjLS6RO8Y2JilJOToz179rh/IJfhrp+n7OxsWa1W+fk5fw5pZZ7D8+fPKz093en14+Pjo+joaMfr52JpaWlO/aUL56K4f1lek5XJlTFe7OzZs8rPz1dISIhT+6ZNmxQaGqpmzZpp8ODB+vnnn91ae1m4Or7c3Fw1aNBA9erVU8+ePZ1eR950Dt1x/ubPn68+ffqoevXqTu3ecP5ccaXXoDues7IwzScoXwvsdrsklfgai7CwMMc6u92u0NBQp/V+fn4KCQlx9Kks7qhl/vz5atGihW677Tan9okTJ6pz586qVq2a1q9fr7/97W/Kzc3VsGHD3Fb/lbg6voceekgNGjRQeHi4vvrqKz3zzDPav3+/li9f7thvaee4eF1lcsc5/OmnnzRp0iQNGjTIqb2yz+FPP/2kwsLCUp/bb775ptRtLnUufvt6K267VJ/K5MoYL/bMM88oPDzc6Y9Ht27d1Lt3bzVq1EiHDx/W3//+d3Xv3l1paWny9fV16xgux5XxNWvWTAsWLFCrVq2UnZ2tmTNn6rbbbtOePXt0/fXXe9U5vNrzt2PHDn399deaP3++U7u3nD9XXOo1mJOTo19//VW//PLLVf/MlwVh5yLPPvuspk2bdtk++/btU/PmzSupIvcr6xiv1q+//qolS5Zo7NixJdb9tu2WW27RmTNnNGPGDLf8oazo8f32j35kZKTq1q2rLl266PDhw2rSpInL+y2PyjqHOTk5io2NVUREhMaPH++0riLPIVwzdepULV26VJs2bXK6iLdPnz6O/4+MjFSrVq3UpEkTbdq0SV26dPFEqWUWFRWlqKgox+PbbrtNLVq00KuvvqpJkyZ5sDL3mz9/viIjI9WuXTun9mv5/HkLws5FRo4cqQEDBly2T+PGjV3at81mkyRlZmaqbt26jvbMzEy1bt3a0efkyZNO2xUUFOjUqVOO7a9WWcd4tbW8++67Onv2rB555JEr9m3fvr0mTZqkvLy8q/7+lMoaX7H27dtLkg4dOqQmTZrIZrOVuJMgMzNTkq6pc3j69Gl169ZNNWvW1IoVK1SlSpXL9nfnOSxN7dq15evr63gui2VmZl5yLDab7bL9y/KarEyujLHYzJkzNXXqVG3YsEGtWrW6bN/GjRurdu3aOnToUKX+sbya8RWrUqWKbrnlFh06dEiSd53DqxnfmTNntHTpUk2cOPGKx/HU+XPFpV6DVqtVVatWla+v71X/TJSJ267++R0r7wXKM2fOdLRlZ2eXeoHyzp07HX3WrVvn0QuUXa2lU6dOJe7guZTJkycb1113ncu1usJdz/Unn3xiSDK+/PJLwzD+7wLl395J8OqrrxpWq9U4d+6c+wZQBq6OMTs72+jQoYPRqVMn48yZM2U6VmWcw3bt2hlDhgxxPC4sLDT+8Ic/XPYC5T/96U9ObVFRUSUuUL7ca7KylXeMhmEY06ZNM6xWq5GWllamYxw7dsywWCzGe++9d9X1lpcr4/utgoICo1mzZsZTTz1lGIb3nUNXx5eSkmIEBAQYP/300xWP4cnz91sq4wXKLVu2dGrr27dviQuUr+Znoky1um1Pv0PfffedsWvXLset1bt27TJ27drldIt1s2bNjOXLlzseT5061QgODjbee+8946uvvjJ69uxZ6q3nt9xyi7F9+3bjk08+MZo2berRW88vV8v3339vNGvWzNi+fbvTdgcPHjQsFouxZs2aEvt8//33jddff93YvXu3cfDgQePll182qlWrZowbN67Cx3Ox8o7v0KFDxsSJE42dO3caR44cMd577z2jcePGxp133unYpvjW865duxpffPGFsXbtWqNOnToevfW8PGPMzs422rdvb0RGRhqHDh1yut21oKDAMAzPncOlS5caAQEBxsKFC429e/cagwYNMoKDgx13vvXv39949tlnHf0//fRTw8/Pz5g5c6axb98+47nnniv11vMrvSYrU3nHOHXqVMPf39949913nc5V8e+h06dPG6NGjTLS0tKMI0eOGBs2bDBuvfVWo2nTppUevl0Z34QJE4x169YZhw8fNtLT040+ffoYgYGBxp49exx9vOkclnd8xTp27Gg8+OCDJdq97fydPn3a8bdOkjFr1ixj165dxnfffWcYhmE8++yzRv/+/R39i289Hz16tLFv3z4jOTm51FvPL/ecuQNh5yrEx8cbkkosH330kaOP/v9nkRQrKioyxo4da4SFhRkBAQFGly5djP379zvt9+effzb69u1r1KhRw7BarcbAgQOdAlRlulItR44cKTFmwzCMpKQko169ekZhYWGJfa5Zs8Zo3bq1UaNGDaN69erGzTffbMybN6/UvhWtvOPLyMgw7rzzTiMkJMQICAgwbrjhBmP06NFOn7NjGIZx9OhRo3v37kbVqlWN2rVrGyNHjnS6bbsylXeMH330Uak/15KMI0eOGIbh2XM4d+5co379+oa/v7/Rrl07Y9u2bY51nTp1MuLj4536v/POO8aNN95o+Pv7GzfddJPxwQcfOK0vy2uyspVnjA0aNCj1XD333HOGYRjG2bNnja5duxp16tQxqlSpYjRo0MB47LHH3PqHpLzKM77hw4c7+oaFhRk9evQwPv/8c6f9eds5LO/P6DfffGNIMtavX19iX952/i71+6F4TPHx8UanTp1KbNO6dWvD39/faNy4sdPfxGKXe87cwWIYlXy/LwAAQCXic3YAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAmNZdd92l4cOHe7oMAB5G2AHgle69915169at1HUff/yxLBaLvvrqq0quCsC1iLADwCslJCQoNTVV33//fYl1KSkpatu27RW/3RsAJMIOAC/1pz/9SXXq1NHChQud2nNzc7Vs2TL16tVLffv21R/+8AdVq1ZNkZGReuutty67T4vFopUrVzq1BQcHOx3j2LFjeuCBBxQcHKyQkBD17NlTR48edc+gAHgEYQeAV/Lz89MjjzyihQsX6rdf4bds2TIVFhbq4YcfVps2bfTBBx/o66+/1qBBg9S/f3/t2LHD5WPm5+crJiZGNWvW1Mcff6xPP/1UNWrUULdu3XT+/Hl3DAuABxB2AHitRx99VIcPH9bmzZsdbSkpKYqLi1ODBg00atQotW7dWo0bN9bQoUPVrVs3vfPOOy4f7+2331ZRUZH+/e9/KzIyUi1atFBKSooyMjK0adMmN4wIgCcQdgB4rebNm+u2227TggULJEmHDh3Sxx9/rISEBBUWFmrSpEmKjIxUSEiIatSooXXr1ikjI8Pl43355Zc6dOiQatasqRo1aqhGjRoKCQnRuXPndPjwYXcNC0Al8/N0AQBwOQkJCRo6dKiSk5OVkpKiJk2aqFOnTpo2bZpefPFFzZkzR5GRkapevbqGDx9+2bebLBaL01ti0oW3rorl5uaqTZs2Wrx4cYlt69Sp475BAahUhB0AXu2BBx7Qk08+qSVLluiNN97Q4MGDZbFY9Omnn6pnz556+OGHJUlFRUU6cOCAIiIiLrmvOnXq6MSJE47HBw8e1NmzZx2Pb731Vr399tsKDQ2V1WqtuEEBqFS8jQXAq9WoUUMPPvigkpKSdOLECQ0YMECS1LRpU6Wmpmrr1q3at2+fHn/8cWVmZl52X507d9a//vUv7dq1Szt37tQTTzyhKlWqONb369dPtWvXVs+ePfXxxx/ryJEj2rRpk4YNG1bqLfAArg2EHQBeLyEhQb/88otiYmIUHh4uSRozZoxuvfVWxcTE6K677pLNZlOvXr0uu58XXnhB9erV0x133KGHHnpIo0aNUrVq1Rzrq1Wrpi1btqh+/frq3bu3WrRooYSEBJ07d46ZHuAaZjEufgMbAADARJjZAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApvb/APW8wsyEgX8IAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "A_data = lds_model.A.data.cpu().numpy()\n",
    "plt.hist(A_data, bins=100, alpha=0.75)\n",
    "plt.title('Histogram of lds.A')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New LDS model with kx=10 created and initialized.\n"
     ]
    }
   ],
   "source": [
    "# Create a new LDS with kx = 10\n",
    "new_lds_kx10 = LDS(state_dim=lds_model.state_dim, input_dim=lds_model.input_dim, output_dim=lds_model.output_dim, kx=50).to(device)\n",
    "\n",
    "# Copy parameters from the original LDS model\n",
    "new_lds_kx10.h0.data = lds_model.h0.data.clone()\n",
    "new_lds_kx10.B.data = lds_model.B.data.clone()\n",
    "new_lds_kx10.C.data = lds_model.C.data.clone()\n",
    "\n",
    "# Move low-order diagonal terms to the matrix connections\n",
    "low_order_A = lds_model.A.clone()\n",
    "low_order_A[(low_order_A > 0.7) | (low_order_A < -0.7)] = 0\n",
    "\n",
    "M = torch.zeros(new_lds_kx10.M.shape)\n",
    "for i in range(50):  # Encompasses low order terms or so\n",
    "    M[:, :, i] = (new_lds_kx10.C.T @ (new_lds_kx10.B * low_order_A).T)\n",
    "\n",
    "new_lds_kx10.M.data = M\n",
    "# Set all terms with low magnitude in A to 0\n",
    "threshold = 0.7  # Define a threshold for low magnitude\n",
    "A_new = lds_model.A.detach().clone()\n",
    "A_new[torch.abs(A_new) < threshold] = 0\n",
    "new_lds_kx10.A.data = torch.zeros(A_new.shape)\n",
    "\n",
    "lds_model.A.data = low_order_A.clone()\n",
    "\n",
    "print(\"New LDS model with kx=10 created and initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs from new_lds_kx10:\n",
      "tensor([[[ 0.1239, -0.0006,  0.0172,  ..., -0.0154,  0.0364, -0.0091],\n",
      "         [-0.0012,  0.0016,  0.0083,  ...,  0.0222, -0.1528,  0.0819],\n",
      "         [-0.0658,  0.0404,  0.0418,  ...,  0.0120,  0.2279,  0.0225],\n",
      "         ...,\n",
      "         [-0.0991, -0.1607,  0.0120,  ...,  0.0182, -0.2866, -0.0342],\n",
      "         [-0.0183, -0.1975,  0.0159,  ...,  0.0319, -0.1280, -0.0635],\n",
      "         [-0.0708, -0.1178,  0.0105,  ...,  0.0152, -0.1076, -0.0723]]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Outputs from lds_model:\n",
      "tensor([[[ 1.4804e-01, -1.3836e-02,  1.2729e-02,  ..., -2.9600e-02,\n",
      "           8.2252e-02,  2.5816e-03],\n",
      "         [-1.1196e-02, -3.4558e-03,  8.7294e-03,  ...,  1.6984e-02,\n",
      "          -1.3149e-01,  7.6630e-02],\n",
      "         [-3.2758e-02,  1.9313e-02,  4.3930e-02,  ..., -1.0055e-03,\n",
      "           3.1026e-01,  5.4414e-03],\n",
      "         ...,\n",
      "         [-5.1858e-02,  1.6662e-02,  1.3790e-02,  ...,  1.6665e-02,\n",
      "          -2.4579e-01,  1.3395e-02],\n",
      "         [ 1.3173e-02, -4.1623e-02,  1.6496e-02,  ...,  2.1493e-02,\n",
      "          -1.1408e-01, -1.0588e-03],\n",
      "         [-4.0034e-02,  5.2380e-02,  5.8044e-03,  ...,  4.2121e-05,\n",
      "          -2.0925e-01,  1.2784e-02]]], device='cuda:0')\n",
      "\n",
      "Are the outputs similar? 0.1022781953215599\n"
     ]
    }
   ],
   "source": [
    "# Prepare some input data\n",
    "inputs = torch.randn(1, 1024, 768).to(device).to(torch.float)\n",
    "\n",
    "# Run the input through new_lds_kx10\n",
    "new_lds_kx10.to(device).eval()\n",
    "with torch.no_grad():\n",
    "    new_lds_kx10_outputs = new_lds_kx10(inputs)\n",
    "\n",
    "# Run the input through lds_model\n",
    "lds_model.to(device).eval()\n",
    "with torch.no_grad():\n",
    "    lds_model_outputs = lds_model(inputs)\n",
    "\n",
    "# Compare the outputs\n",
    "print(\"Outputs from new_lds_kx10:\")\n",
    "print(new_lds_kx10_outputs)\n",
    "\n",
    "print(\"\\nOutputs from lds_model:\")\n",
    "print(lds_model_outputs)\n",
    "\n",
    "# Check if the outputs are similar\n",
    "similarity = torch.abs(new_lds_kx10_outputs - lds_model_outputs).mean()\n",
    "print(f\"\\nAre the outputs similar? {similarity}\")\n",
    "\n",
    "#I don't know what the issue is, perhaps the problem is h0 being non-zero? So test with h0 = 0 for both models and see if that works better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered LDS model created and initialized.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1041"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find indices where lds.A is not zero\n",
    "non_zero_indices = (new_lds.A != 0).nonzero(as_tuple=True)[0]\n",
    "\n",
    "# Filter B and C based on non-zero indices\n",
    "B_filtered = new_lds.B[:, non_zero_indices].clone()\n",
    "C_filtered = new_lds.C[non_zero_indices, :].clone()\n",
    "\n",
    "# Create a new LDS with the filtered B and C\n",
    "filtered_state_dim = len(non_zero_indices)\n",
    "new_lds_filtered = LDS(filtered_state_dim, new_lds.input_dim, new_lds.output_dim, kx=new_lds.kx).to(device)\n",
    "new_lds_filtered.B.data = B_filtered\n",
    "new_lds_filtered.C.data = C_filtered\n",
    "new_lds_filtered.A.data = new_lds.A[non_zero_indices].clone()\n",
    "\n",
    "print(\"Filtered LDS model created and initialized.\")\n",
    "filtered_state_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert lds.A to a numpy array and plot the histogram\n",
    "A_data = new_lds_filtered.A.data.cpu().numpy()\n",
    "plt.hist(A_data, bins=100, alpha=0.75)\n",
    "plt.title('Histogram of lds.A')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of values over 0.9: 33.74%\n"
     ]
    }
   ],
   "source": [
    "percent_over_0_9 = np.sum(A_data > 0.9) / len(A_data) * 100\n",
    "print(f\"Percentage of values over 0.9: {percent_over_0_9:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LDS' object has no attribute 'phi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m stu \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstu)\n\u001b[1;32m----> 2\u001b[0m stu\u001b[38;5;241m.\u001b[39mphi \u001b[38;5;241m=\u001b[39m \u001b[43mstu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphi\u001b[49m\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mbfloat16)\n\u001b[0;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(new_lds_filtered\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m)\n\u001b[0;32m      5\u001b[0m lds_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2001\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\devan\\anaconda3\\envs\\flashstu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1933\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LDS' object has no attribute 'phi'"
     ]
    }
   ],
   "source": [
    "stu = copy.deepcopy(model.layers[0].stu)\n",
    "stu.phi = stu.phi.to(torch.bfloat16)\n",
    "\n",
    "optimizer = torch.optim.Adam(new_lds_filtered.parameters(), lr = 0.0001)\n",
    "lds_epochs = 2001\n",
    "lds_loss_values = []\n",
    "\n",
    "for epoch in range(lds_epochs):\n",
    "    inputs = torch.randn(5, 4096, 768).to(device).to(torch.bfloat16)\n",
    "    stu_outputs = stu(inputs).to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = new_lds_filtered.compute_loss(inputs.to(stu_outputs.dtype), stu_outputs)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(new_lds_filtered.parameters(), max_norm=1)\n",
    "    lds_loss_values.append(loss.item())\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        new_lds_filtered.A.data.clamp_(max=1, min = -1)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-12 23:09:10,521 - INFO - Found 1 shards for split val\n"
     ]
    }
   ],
   "source": [
    "from dataloader import DataLoader\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    bsz=1,\n",
    "    seq_len=seq_len, \n",
    "    dataset='./fineweb-edu', \n",
    "    split=\"val\", \n",
    "    main_process=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.amp import autocast\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "def evaluate(model):\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "    val_loss = 0.0\n",
    "    torch_dtype = getattr(torch, 'bfloat16')\n",
    "    val_steps = 5 # Arbitrarily set to reduce long evaluations, >20 typically used\n",
    "    model.eval()\n",
    "    val_loader.reset()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in zip(range(val_steps), val_loader, strict=False):\n",
    "            inputs, targets = batch\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            if torch_dtype != torch.float32:\n",
    "                with autocast(device_type=device.type, dtype=torch_dtype, cache_enabled=True):\n",
    "                    preds = model(inputs)\n",
    "            else:\n",
    "                preds = model(inputs)\n",
    "\n",
    "            loss = loss_fn(preds.flatten(0, 1), targets.flatten(0, 1))\n",
    "            loss = loss / val_steps\n",
    "            val_loss += loss.detach().float()\n",
    "    return(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.8516, device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stu = copy.deepcopy(model.layers[0].stu)\n",
    "model.layers[0].stu = lds_model.to(device)\n",
    "evaluate(model)\n",
    "\n",
    "#FOR SOME REASON, THE NEW LDS underperforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 0.07866311073303223\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Generate random input\n",
    "random_input = torch.randn(1, 1024, 768).to(device).to(torch.bfloat16)\n",
    "\n",
    "# Compute outputs from stu and lds_model\n",
    "stu.phi = stu.phi.to(torch.bfloat16)\n",
    "stu_output = stu(random_input)\n",
    "lds_model_output = lds_model(random_input.to(torch.float))\n",
    "\n",
    "# Compute MSE loss\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "mse_loss = mse_loss_fn(stu_output, lds_model_output)\n",
    "\n",
    "print(f\"MSE Loss: {mse_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_lds.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.2266, device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stu = copy.deepcopy(model.layers[0].stu)\n",
    "model.layers[0].stu = new_lds.to(device) #filtered, slow\n",
    "evaluate(model)\n",
    "\n",
    "#FOR SOME REASON, THE NEW LDS underperforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.6250, device='cuda:0')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stu = copy.deepcopy(model.layers[0].stu)\n",
    "model.layers[0].stu = new_lds_filtered.to(device) #filtered, fast\n",
    "evaluate(model)\n",
    "\n",
    "#FOR SOME REASON, THE NEW LDS underperforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 768])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lds_filtered = new_lds_filtered.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_t = new_lds_filtered.h0.expand(1, new_lds_filtered.state_dim).to(device)\n",
    "A = new_lds_filtered.A.flatten()\n",
    "all_h_t = []\n",
    "for t in range(1024):\n",
    "    u_t = inputs[:, t, :]\n",
    "    h_t = A * h_t + (u_t @ new_lds_filtered.B)\n",
    "    all_h_t.append(h_t.unsqueeze(1))\n",
    "all_h_t = torch.cat(all_h_t, dim=1)\n",
    "lds_out = torch.matmul(all_h_t, new_lds_filtered.C)\n",
    "new_ht = lds_out.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0559, -0.0489, -0.0393,  ..., -0.0129, -0.0298, -0.0301],\n",
       "         [ 0.0111,  0.1352, -0.0287,  ..., -0.1449,  0.0984, -0.0868],\n",
       "         [ 0.0075, -0.2174, -0.0297,  ...,  0.1494,  0.1317,  0.0024],\n",
       "         ...,\n",
       "         [-0.1460,  0.0488, -0.2218,  ..., -0.0125, -0.1097,  0.1176],\n",
       "         [-0.1231,  0.0952,  0.0334,  ..., -0.0448, -0.0257, -0.0463],\n",
       "         [-0.1197,  0.0074,  0.1675,  ..., -0.1491, -0.0926, -0.1805]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ht + compute_ar_x_preds(new_lds_filtered.M,inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "lds_model= lds_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_t = lds_model.h0.expand(1, lds_model.state_dim).to(device)\n",
    "A = lds_model.A.flatten()\n",
    "all_h_t = []\n",
    "for t in range(1024):\n",
    "    u_t = inputs[:, t, :]\n",
    "    h_t = A * h_t + (u_t @ lds_model.B)\n",
    "    all_h_t.append(h_t.unsqueeze(1))\n",
    "all_h_t = torch.cat(all_h_t, dim=1)\n",
    "lds_out = torch.matmul(all_h_t, lds_model.C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0369, -0.1756, -0.0140,  ..., -0.0095,  0.2034,  0.2664],\n",
       "         [-0.0109, -0.1869, -0.1448,  ..., -0.0877, -0.2060, -0.1952],\n",
       "         [-0.3321,  0.3115, -0.0473,  ..., -0.2979, -0.5652, -0.3678],\n",
       "         ...,\n",
       "         [-0.0103, -0.1460,  0.1361,  ..., -0.0476, -0.1077, -0.1046],\n",
       "         [-0.0336, -0.2587,  0.1905,  ...,  0.1077, -0.0199, -0.0399],\n",
       "         [ 0.1209, -0.1252, -0.2284,  ..., -0.1752, -0.1115,  0.1808]]],\n",
       "       device='cuda:0', grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can we remove D\n",
    "# finetune model after residual\n",
    "# factorization\n",
    "# is gaussian most realistic input data (uniform?, from data)\n",
    "# greedy fitting\n",
    "\n",
    "#why does an LDS exist that fits the STU\n",
    "#why does gradient descent find it\n",
    "\n",
    "#stu filters are 24 dim subspace of R^L, this subclass captures LDSs,\n",
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-0.9963, device='cuda:0'),\n",
       " tensor(-0.9950, device='cuda:0'),\n",
       " tensor(-0.9950, device='cuda:0'),\n",
       " tensor(-0.9949, device='cuda:0'),\n",
       " tensor(-0.9948, device='cuda:0')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(lds.A.data)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.9945, device='cuda:0'),\n",
       " tensor(0.9948, device='cuda:0'),\n",
       " tensor(0.9958, device='cuda:0'),\n",
       " tensor(0.9960, device='cuda:0'),\n",
       " tensor(0.9960, device='cuda:0')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(lds.A.data)[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devan\\AppData\\Local\\Temp\\ipykernel_21096\\3432883371.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lds_layer_0.load_state_dict(torch.load(\"./lds_layer_0.pt\"))\n",
      "C:\\Users\\devan\\AppData\\Local\\Temp\\ipykernel_21096\\3432883371.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lds_layer_2.load_state_dict(torch.load(\"./lds_layer_2.pt\"))\n",
      "C:\\Users\\devan\\AppData\\Local\\Temp\\ipykernel_21096\\3432883371.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lds_layer_4.load_state_dict(torch.load(\"./lds_layer_4.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.224609375\n"
     ]
    }
   ],
   "source": [
    "# Load LDS models for layers 0, 2, and 4\n",
    "\n",
    "lds_layer_0 = LDS(10000, 768, 768).to(device)\n",
    "lds_layer_0.load_state_dict(torch.load(\"./lds_layer_0.pt\"))\n",
    "\n",
    "lds_layer_2 = LDS(10000, 768, 768).to(device)\n",
    "lds_layer_2.load_state_dict(torch.load(\"./lds_layer_2.pt\"))\n",
    "\n",
    "lds_layer_4 = LDS(10000, 768, 768).to(device)\n",
    "lds_layer_4.load_state_dict(torch.load(\"./lds_layer_4.pt\"))\n",
    "\n",
    "# Substitute LDS models into model2\n",
    "model2.layers[0].stu = lds_layer_0\n",
    "model2.layers[2].stu = lds_layer_2\n",
    "model2.layers[4].stu = lds_layer_4\n",
    "\n",
    "# Run evaluation\n",
    "val_loss = evaluate(model2)\n",
    "print(f\"Validation Loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.3359375\n"
     ]
    }
   ],
   "source": [
    "model2 =  copy.deepcopy(model)\n",
    "model2.layers[0].stu = lds_layer_0\n",
    "# model2.layers[2].stu = lds_layer_2\n",
    "model2.layers[4].stu = lds_layer_4\n",
    "val_loss = evaluate(model2)\n",
    "print(f\"Validation Loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8779, device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlashSTU(\n",
       "  (tok_emb): Embedding(200064, 768)\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): STULayer(\n",
       "      (stu_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (stu): STU()\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): AttentionLayer(\n",
       "      (attn_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (c_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): STULayer(\n",
       "      (stu_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (stu): STU()\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): AttentionLayer(\n",
       "      (attn_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (c_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): STULayer(\n",
       "      (stu_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (stu): LDS()\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): AttentionLayer(\n",
       "      (attn_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (c_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): STULayer(\n",
       "      (stu_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (stu): STU()\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): AttentionLayer(\n",
       "      (attn_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (c_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): STULayer(\n",
       "      (stu_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (stu): STU()\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): AttentionLayer(\n",
       "      (attn_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (c_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): STULayer(\n",
       "      (stu_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (stu): STU()\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): AttentionLayer(\n",
       "      (attn_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (c_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "  (lm_head): Linear(in_features=768, out_features=200064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[4].stu = stu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlashSTU(\n",
       "  (tok_emb): Embedding(200064, 768)\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): STULayer(\n",
       "      (stu_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (stu): STU()\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): AttentionLayer(\n",
       "      (attn_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (c_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): STULayer(\n",
       "      (stu_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (stu): STU()\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): AttentionLayer(\n",
       "      (attn_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (c_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): STULayer(\n",
       "      (stu_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (stu): LDS()\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): AttentionLayer(\n",
       "      (attn_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (c_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): STULayer(\n",
       "      (stu_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (stu): STU()\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): AttentionLayer(\n",
       "      (attn_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (c_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): STULayer(\n",
       "      (stu_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (stu): STU()\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): AttentionLayer(\n",
       "      (attn_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (c_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): STULayer(\n",
       "      (stu_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (stu): STU()\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): AttentionLayer(\n",
       "      (attn_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (c_attn): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (c_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (mlp_norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=768, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm((768,), eps=None, elementwise_affine=True)\n",
       "  (lm_head): Linear(in_features=768, out_features=200064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
