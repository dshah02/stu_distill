{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from flashfftconv import FlashFFTConv\n",
    "\n",
    "    flash_fft_available = True\n",
    "except ImportError as e:\n",
    "    print(\n",
    "        f\"Unable to import FlashFFTConv: {e}. Falling back to PyTorch implementation.\"\n",
    "    )\n",
    "    flash_fft_available = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ds6237/.conda/envs/torch-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from model_550m import STU, flash_convolve\n",
    "import time\n",
    "import random\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lds import LDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_99284/231399206.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  stu_layer_full = torch.load(f\"../stu_layers/stu_layer_{layer_i}_550m_param_full.pt\", map_location=device)\n"
     ]
    }
   ],
   "source": [
    "layer_i = 2\n",
    "state_dim = 1000\n",
    "seq_len = 512\n",
    "kx = 5\n",
    "lr = 0.0001\n",
    "epochs = 5000\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the layer i weights\n",
    "stu_layer_full = torch.load(f\"../stu_layers/stu_layer_{layer_i}_550m_param_full.pt\", map_location=device)\n",
    "stu_layer_full.eval()\n",
    "\n",
    "# Initialize LDS model\n",
    "lds = LDS(state_dim, 896, 896, kx).to(device)\n",
    "optimizer = torch.optim.Adam(lds.parameters(), lr=lr)\n",
    "\n",
    "# Training\n",
    "lds_loss_values = []\n",
    "\n",
    "best_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = stu_layer_full.stu_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_stu_impulse_approx(stu, seq_len=1000):\n",
    "    \"\"\"\n",
    "    Generate the impulse response of a STU model with approximation.\n",
    "    \n",
    "    Args:\n",
    "        stu: The STU model\n",
    "        seq_len: Length of the impulse response\n",
    "        \n",
    "    Returns:\n",
    "        impulse_response: The impulse response of the STU model with shape (seq_len, d_out, d_in)\n",
    "    \"\"\"\n",
    "    # Create an impulse input\n",
    "    batch_size = 1\n",
    "    d_in = stu.d_in\n",
    "    d_out = stu.d_out\n",
    "    impulse = torch.zeros((batch_size, seq_len, d_in), device=stu.M_inputs.device if hasattr(stu, 'M_inputs') else 'cpu')\n",
    "    \n",
    "    # Initialize the output tensor with the correct shape (seq_len, d_out, d_in)\n",
    "    impulse_response = torch.zeros((seq_len, d_out, d_in), device=impulse.device)\n",
    "    \n",
    "    # For each input dimension, create an impulse and get the response\n",
    "    for i in range(d_in):\n",
    "        # Reset the impulse tensor\n",
    "        impulse.zero_()\n",
    "        # Set the impulse for the current input dimension\n",
    "        impulse[:, 0, i] = 1.0\n",
    "        \n",
    "        # Pass the impulse through the STU model\n",
    "        with torch.no_grad():\n",
    "            if stu.use_approx:\n",
    "                # Project the impulse using M_inputs\n",
    "                impulse_proj = impulse @ stu.M_inputs.float()\n",
    "                \n",
    "                # Project the filters using M_filters\n",
    "                phi_proj = stu.stu_filters.float() @ stu.M_filters.float()\n",
    "                \n",
    "                # Compute the convolution\n",
    "                if stu.flash_fft:\n",
    "                    spectral_plus, spectral_minus = flash_convolve(\n",
    "                        impulse_proj, phi_proj, stu.flash_fft, stu.use_approx\n",
    "                    )\n",
    "                else:\n",
    "                    spectral_plus, spectral_minus = convolve(\n",
    "                        impulse_proj, phi_proj, stu.n, stu.use_approx\n",
    "                    )\n",
    "                \n",
    "                # The impulse response for this input dimension\n",
    "                response = spectral_plus if stu.use_hankel_L else spectral_plus + spectral_minus\n",
    "            else:\n",
    "                # For non-approximation case, use the original forward pass\n",
    "                response = stu(impulse)\n",
    "            \n",
    "            # Store the response for this input dimension\n",
    "            impulse_response[:, :, i] = response.squeeze(0).float()\n",
    "    \n",
    "    return impulse_response.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stu_impulse = gen_stu_impulse_approx(stu_layer_full, seq_len = seq_len)\n",
    "stu_impulse = torch.Tensor(stu_impulse).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(stu_impulse.cpu(), \"filter_2_impulse.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(stu_layer_full.stu_filters.cpu(), \"phi.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 896, 896])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stu_impulse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.3862888813018799\n",
      "Epoch 10, Loss: 1.2970925569534302\n",
      "Epoch 20, Loss: 1.2136180400848389\n",
      "Epoch 30, Loss: 1.130974531173706\n",
      "Epoch 40, Loss: 1.0482280254364014\n",
      "Epoch 50, Loss: 0.9663774967193604\n",
      "Epoch 60, Loss: 0.8869189023971558\n",
      "Epoch 70, Loss: 0.8111565709114075\n",
      "Epoch 80, Loss: 0.7400259971618652\n",
      "Epoch 90, Loss: 0.6740994453430176\n",
      "Epoch 100, Loss: 0.6136292219161987\n",
      "Epoch 110, Loss: 0.5586282014846802\n",
      "Epoch 120, Loss: 0.5089318752288818\n",
      "Epoch 130, Loss: 0.4642542004585266\n",
      "Epoch 140, Loss: 0.42424604296684265\n",
      "Epoch 150, Loss: 0.38852909207344055\n",
      "Epoch 160, Loss: 0.35671648383140564\n",
      "Epoch 170, Loss: 0.3284258544445038\n",
      "Epoch 180, Loss: 0.30328789353370667\n",
      "Epoch 190, Loss: 0.2809535264968872\n",
      "Epoch 200, Loss: 0.2610991597175598\n",
      "Epoch 210, Loss: 0.243429034948349\n",
      "Epoch 220, Loss: 0.2276766300201416\n",
      "Epoch 230, Loss: 0.21360471844673157\n",
      "Epoch 240, Loss: 0.20100253820419312\n",
      "Epoch 250, Loss: 0.1896858960390091\n",
      "Epoch 260, Loss: 0.17949363589286804\n",
      "Epoch 270, Loss: 0.17028550803661346\n",
      "Epoch 280, Loss: 0.16194044053554535\n",
      "Epoch 290, Loss: 0.15435254573822021\n",
      "Epoch 300, Loss: 0.14743146300315857\n",
      "Epoch 310, Loss: 0.14109855890274048\n",
      "Epoch 320, Loss: 0.1352861225605011\n",
      "Epoch 330, Loss: 0.1299356073141098\n",
      "Epoch 340, Loss: 0.12499593943357468\n",
      "Epoch 350, Loss: 0.12042292207479477\n",
      "Epoch 360, Loss: 0.11617831140756607\n",
      "Epoch 370, Loss: 0.11222866177558899\n",
      "Epoch 380, Loss: 0.10854440182447433\n",
      "Epoch 390, Loss: 0.10509996861219406\n",
      "Epoch 400, Loss: 0.10187271237373352\n",
      "Epoch 410, Loss: 0.0988425761461258\n",
      "Epoch 420, Loss: 0.09599200636148453\n",
      "Epoch 430, Loss: 0.09330525249242783\n",
      "Epoch 440, Loss: 0.09076839685440063\n",
      "Epoch 450, Loss: 0.08836915343999863\n",
      "Epoch 460, Loss: 0.08609633892774582\n",
      "Epoch 470, Loss: 0.08393995463848114\n",
      "Epoch 480, Loss: 0.08189123123884201\n",
      "Epoch 490, Loss: 0.07994204014539719\n",
      "Epoch 500, Loss: 0.07808510214090347\n",
      "Epoch 510, Loss: 0.07631415873765945\n",
      "Epoch 520, Loss: 0.07462295144796371\n",
      "Epoch 530, Loss: 0.07300623506307602\n",
      "Epoch 540, Loss: 0.0714593231678009\n",
      "Epoch 550, Loss: 0.0699775293469429\n",
      "Epoch 560, Loss: 0.06855686008930206\n",
      "Epoch 570, Loss: 0.06719359010457993\n",
      "Epoch 580, Loss: 0.0658843144774437\n",
      "Epoch 590, Loss: 0.06462609767913818\n",
      "Epoch 600, Loss: 0.06341581791639328\n",
      "Epoch 610, Loss: 0.06225094571709633\n",
      "Epoch 620, Loss: 0.061129093170166016\n",
      "Epoch 630, Loss: 0.06004776433110237\n",
      "Epoch 640, Loss: 0.05900498107075691\n",
      "Epoch 650, Loss: 0.057998936623334885\n",
      "Epoch 660, Loss: 0.057027366012334824\n",
      "Epoch 670, Loss: 0.05608915537595749\n",
      "Epoch 680, Loss: 0.05518219992518425\n",
      "Epoch 690, Loss: 0.054305288940668106\n",
      "Epoch 700, Loss: 0.05345699191093445\n",
      "Epoch 710, Loss: 0.05263584852218628\n",
      "Epoch 720, Loss: 0.05184083804488182\n",
      "Epoch 730, Loss: 0.05107073858380318\n",
      "Epoch 740, Loss: 0.050324488431215286\n",
      "Epoch 750, Loss: 0.04960112273693085\n",
      "Epoch 760, Loss: 0.04889943078160286\n",
      "Epoch 770, Loss: 0.048218708485364914\n",
      "Epoch 780, Loss: 0.047558024525642395\n",
      "Epoch 790, Loss: 0.04691663756966591\n",
      "Epoch 800, Loss: 0.04629378020763397\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # Get model parameters\n",
    "    A = lds.A\n",
    "    B = lds.B\n",
    "    C = lds.C\n",
    "    M = lds.M\n",
    "    \n",
    "    # Compute loss by summing (C.T @ A^i @ B.T + M[:,:,i] - stu_impulse[i])**2 directly\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i in range(seq_len):\n",
    "        # Compute C @ A^i @ B directly for the impulse response at time i\n",
    "        # This is equivalent to computing the impulse response at time i\n",
    "        x = B.T\n",
    "        x = (A**i).reshape(-1,1) * x\n",
    "        y_pred = C.T @ x\n",
    "        \n",
    "        # Add M[:,:,i] for the first kx steps\n",
    "        if i < kx:\n",
    "            y_pred = y_pred + M[:,:,i]\n",
    "        \n",
    "        # Compute squared error with stu_impulse[i]\n",
    "        squared_error = torch.sum((y_pred - stu_impulse[i])**2)\n",
    "        running_loss += squared_error\n",
    "    \n",
    "    # Compute mean squared error\n",
    "    total_loss = running_loss / seq_len\n",
    "    total_loss.backward()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm_(lds.parameters(), max_norm=1)\n",
    "    lds_loss_values.append(total_loss.item())\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        lds.A.data.clamp_(max=1, min=-1)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lds.state_dict(), \"filter_2_impulse.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the impulse response of the trained LDS model\n",
    "with torch.no_grad():\n",
    "    lds_impulse = lds.impulse(seq_len=stu_impulse.shape[0])\n",
    "\n",
    "# Print shapes for verification\n",
    "print(f\"LDS impulse shape: {lds_impulse.shape}\")\n",
    "print(f\"STU impulse shape: {stu_impulse.shape}\")\n",
    "\n",
    "# Compute the mean squared error between the two impulse responses\n",
    "mse = torch.mean((lds_impulse - stu_impulse) ** 2)\n",
    "print(f\"Mean Squared Error between LDS and STU impulse: {mse.item()}\")\n",
    "\n",
    "# Visualize a few impulse responses for comparison\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select a few input-output pairs to visualize\n",
    "input_idx = 10  # First input dimension\n",
    "output_indices = [0, 1]  # First two output dimensions\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, output_idx in enumerate(output_indices):\n",
    "    plt.subplot(len(output_indices), 1, i+1)\n",
    "    \n",
    "    # Plot LDS impulse response\n",
    "    plt.plot(lds_impulse[:, output_idx, input_idx].cpu().numpy(), \n",
    "             label=f'LDS Impulse (out={output_idx}, in={input_idx})')\n",
    "    \n",
    "    # Plot student impulse response\n",
    "    plt.plot(stu_impulse[:, output_idx, input_idx].cpu().numpy(), \n",
    "             label=f'STU Impulse (out={output_idx}, in={input_idx})')\n",
    "    \n",
    "    plt.title(f'Impulse Response: Output {output_idx}, Input {input_idx}')\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('Response')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test how the models respond to Gaussian input\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate Gaussian input sequence\n",
    "input_dim = stu_impulse.shape[2]  # Get input dimension from the impulse shape\n",
    "batch_size = 1\n",
    "\n",
    "# Create random Gaussian input\n",
    "np.random.seed(42)  # For reproducibility\n",
    "gaussian_input = torch.tensor(np.random.normal(0, 1, (batch_size, seq_len, input_dim)), \n",
    "                             dtype=torch.float32).to(device)\n",
    "\n",
    "# Run both models on the same input\n",
    "with torch.no_grad():\n",
    "    # Get LDS response to Gaussian input\n",
    "    lds_response = lds(gaussian_input)\n",
    "    \n",
    "    # For STU, we need to use the impulse response to compute the output\n",
    "    # This is essentially a convolution of the input with the impulse response\n",
    "    stu_response = torch.zeros((batch_size, seq_len, stu_impulse.shape[1]), \n",
    "                              dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Convolve input with impulse response\n",
    "    for b in range(batch_size):\n",
    "        for t in range(seq_len):\n",
    "            for tau in range(min(t+1, stu_impulse.shape[0])):\n",
    "                stu_response[b, t] += torch.matmul(\n",
    "                    stu_impulse[tau], gaussian_input[b, t-tau]\n",
    "                )\n",
    "\n",
    "# Compute MSE between responses\n",
    "response_mse = torch.mean((lds_response - stu_response) ** 2)\n",
    "print(f\"MSE between LDS and STU responses to Gaussian input: {response_mse.item()}\")\n",
    "\n",
    "# Visualize a few output dimensions\n",
    "output_indices = [0, 1]  # First two output dimensions\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, output_idx in enumerate(output_indices):\n",
    "    plt.subplot(len(output_indices), 1, i+1)\n",
    "    \n",
    "    # Plot LDS response\n",
    "    plt.plot(lds_response[0, :, output_idx].cpu().numpy(), \n",
    "             label=f'LDS Response (out={output_idx})')\n",
    "    \n",
    "    # Plot STU response\n",
    "    plt.plot(stu_response[0, :, output_idx].cpu().numpy(), \n",
    "             label=f'STU Response (out={output_idx})')\n",
    "    \n",
    "    plt.title(f'Response to Gaussian Input: Output {output_idx}')\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('Response')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env [~/.conda/envs/torch-env/]",
   "language": "python",
   "name": "conda_torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
