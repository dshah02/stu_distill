{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2f9aec6-9c5f-4963-9c2f-07bedf39d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tqdm\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "sys.path.append(os.path.abspath(\"./convex_hull\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64cf4453-1788-444c-b270-de42224f90d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ds6237/.conda/envs/torch-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Validation loss: 2.8789, trained on ~59.7B FineWeb-Edu tokens.\n",
    "This is a base model and can frequently hallucinate.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tiktoken\n",
    "from torch import nn\n",
    "\n",
    "from safetensors import safe_open\n",
    "\n",
    "from model_550m import FlashSTU, FlashSTUConfig, get_spectral_filters\n",
    "\n",
    "\n",
    "CHECKPOINT_PATH = \"../models/model_step-114000.safetensors\"\n",
    "CONFIG_PATH = \"../models/config_2-7b.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bbcc1b9-4ebe-4ac9-a3ce-79dca34de58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_compile(model: nn.Module) -> None:\n",
    "    \"\"\"\n",
    "    Apply torch.compile to each layer. This makes compilation efficient\n",
    "    due to repeated structure. Alternatively, one can just compile the whole model.\n",
    "    \"\"\"\n",
    "    print(f\"Compiling each {model.__class__.__name__} layer with torch.compile...\")\n",
    "    start = time.perf_counter()\n",
    "    for idx, layer in model.layers.named_children():\n",
    "        compiled_layer = torch.compile(layer, mode=\"max-autotune\", fullgraph=True)\n",
    "        model.layers.register_module(idx, compiled_layer)\n",
    "    end = time.perf_counter()\n",
    "    print(f\"Finished compiling each {model.__class__.__name__} layer in {end - start:.4f} seconds.\")\n",
    "\n",
    "\n",
    "def load_stu_model(config_path: str, checkpoint_path: str, device: torch.device):\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config_data = json.load(f)\n",
    "\n",
    "    dim = config_data[\"dim\"]\n",
    "    num_heads = config_data[\"num_heads\"]\n",
    "    num_layers = config_data[\"num_layers\"]\n",
    "    num_eigh = config_data[\"num_eigh\"]\n",
    "    seq_len = config_data[\"seq_len\"]\n",
    "    use_hankel_L = config_data[\"use_hankel_L\"]\n",
    "    window_size = config_data[\"window_size\"]\n",
    "    vocab_size = config_data[\"vocab_size\"]\n",
    "    mlp_scale = config_data[\"mlp_scale\"]\n",
    "    bias = config_data[\"bias\"]\n",
    "    dropout = config_data[\"dropout\"]\n",
    "    softcap = config_data[\"softcap\"]\n",
    "    theta = config_data[\"theta\"]\n",
    "    torch_compile = config_data[\"torch_compile\"]\n",
    "    torch_dtype = getattr(torch, config_data[\"torch_dtype\"])\n",
    "\n",
    "    model_config = FlashSTUConfig(\n",
    "        dim=dim,\n",
    "        num_heads=num_heads,\n",
    "        num_layers=num_layers,\n",
    "        seq_len=seq_len,\n",
    "        window_size=window_size,\n",
    "        vocab_size=vocab_size,\n",
    "        mlp_scale=mlp_scale,\n",
    "        bias=bias,\n",
    "        dropout=dropout,\n",
    "        softcap=softcap,\n",
    "        theta=theta,\n",
    "        torch_dtype=torch_dtype,\n",
    "    )\n",
    "\n",
    "    spectral_filters = get_spectral_filters(seq_len, num_eigh, use_hankel_L, device, torch_dtype)\n",
    "    model = FlashSTU(model_config, spectral_filters)\n",
    "    model = model.to(device=device, dtype=torch_dtype)\n",
    "\n",
    "    print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
    "    state_dict = {}\n",
    "    start_time = time()\n",
    "\n",
    "    if checkpoint_path.endswith(\".safetensors\"):\n",
    "        with safe_open(checkpoint_path, framework=\"pt\", device=device.type) as f:\n",
    "            for k in f.keys():\n",
    "                state_dict[k] = f.get_tensor(k)\n",
    "    elif checkpoint_path.endswith(\".pt\"):\n",
    "        state_dict = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported checkpoint format: {checkpoint_path}\")\n",
    "    print(f\"Checkpoint loaded in {time() - start_time:.2f} seconds.\")\n",
    "\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    print(\"Model weights loaded successfully!\")\n",
    "\n",
    "    if torch_compile:\n",
    "        model = apply_compile(model)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    return model, config_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43c051ad-0d01-4b01-9715-f5f6b3959d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    prompt,\n",
    "    num_return_sequences=1,\n",
    "    max_length=512,\n",
    "    device=\"cuda\",\n",
    "    temperature=1.0,\n",
    "    top_k=50,\n",
    "    cache = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate text from the given prompt using top-k sampling.\n",
    "\n",
    "    Args:\n",
    "        model: The FlashSTU model instance.\n",
    "        tokenizer: The tokenizer used for encoding/decoding.\n",
    "        prompt (str): Input prompt text.\n",
    "        num_return_sequences (int): How many sequences to return.\n",
    "        max_length (int): Maximum length of generated tokens.\n",
    "        device: torch device.\n",
    "        temperature (float): Sampling temperature. Higher = more random.\n",
    "        top_k (int): Top-K sampling parameter.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: A list of generated text sequences.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Encode prompt tokens.\n",
    "    tokens = torch.tensor(\n",
    "        [tokenizer.encode(prompt, allowed_special={\"<|endoftext|>\"})],\n",
    "        device=device,\n",
    "    )\n",
    "    seq_len = tokens.shape[1]\n",
    "    tokens = tokens.repeat(num_return_sequences, 1)\n",
    "    \n",
    "    input_pos = torch.arange(seq_len, device=device)\n",
    "\n",
    "    \n",
    "    sample_rng = torch.Generator(device=device)\n",
    "    sample_rng.manual_seed(1746)\n",
    "\n",
    "    eos_token_id = tokenizer.encode(\n",
    "        \"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}\n",
    "    )[0]\n",
    "    cur_token = seq_len\n",
    "    with torch.no_grad():\n",
    "        for idx in tqdm.tqdm(range(max_length - tokens.size(1))):\n",
    "            with torch.amp.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "                # Fwd pass. Inspect logits here.\n",
    "                if not cache:\n",
    "                    logits = model(tokens)\n",
    "                elif idx != 0:\n",
    "                    logits = model(tokens[:, -1:], input_pos = input_pos)     # shape: [batch, 1, vocab]\n",
    "                else:\n",
    "                    logits = model(tokens, input_pos = input_pos)     # shape: [batch, seq, vocab]\n",
    "                logits = logits[:, -1, :]  # last token logits\n",
    "\n",
    "                # Apply temperature scaling.\n",
    "                if temperature > 0:\n",
    "                    logits = logits / temperature\n",
    "\n",
    "            # Compute probabilities.\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "            # Top-K sampling.\n",
    "            top_k_probs, top_k_indices = torch.topk(probs, top_k, dim=-1)\n",
    "            ix = torch.multinomial(top_k_probs, 1, generator=sample_rng)\n",
    "            next_token = torch.gather(top_k_indices, -1, ix)\n",
    "\n",
    "            # Append next token.\n",
    "            tokens = torch.cat((tokens, next_token), dim=1)\n",
    "            input_pos = torch.tensor([cur_token]).to(device)\n",
    "            cur_token +=1 \n",
    "            # Stop if EOS token is generated.\n",
    "            if (next_token == eos_token_id).any():\n",
    "                break\n",
    "\n",
    "    # Decode all sequences.\n",
    "    generated_sequences = []\n",
    "    for i in range(num_return_sequences):\n",
    "        decoded = tokenizer.decode(tokens[i].tolist())\n",
    "        generated_sequences.append(decoded)\n",
    "\n",
    "    return generated_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c729eacd-b0f4-4464-b578-897dc212ca38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tiktoken.load import load_tiktoken_bpe\n",
    "bpe_path = \"../models/o200k_base.tiktoken\"\n",
    "bpe_dict = load_tiktoken_bpe(bpe_path)\n",
    "\n",
    "tokenizer = tiktoken.Encoding(\n",
    "    name=\"o200k_base\",  # Name of the encoding\n",
    "    pat_str=r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+\"\"\",\n",
    "    mergeable_ranks=bpe_dict,\n",
    "    special_tokens={\n",
    "        \"<|endoftext|>\": 199999,  # Custom special token example (modify as needed)\n",
    "        \"<|endofprompt|>\": 200018,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88070375-8af1-4a23-90b0-d0f70644c191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Parameter Count: 550.31M\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ds6237/.conda/envs/torch-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1326: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at /opt/conda/conda-bld/pytorch_1729647378361/work/aten/src/ATen/native/Copy.cpp:308.)\n",
      "  return t.to(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from ../models/model_step-114000.safetensors...\n",
      "Checkpoint loaded in 0.39 seconds.\n",
      "Model weights loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# Load model and config.\n",
    "model, config_data = load_stu_model(CONFIG_PATH, CHECKPOINT_PATH, device)\n",
    "# tokenizer = tiktoken.get_encoding(\"o200k_base\") #need to cache this for offline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcd2dd73-e402-444e-a0d3-29e4c7b33a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 01:48:10,626 - INFO - Found 1 shards for split val\n"
     ]
    }
   ],
   "source": [
    "from torch.amp import autocast\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import tqdm \n",
    "\n",
    "from dataloader import DataLoader\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    bsz=1,\n",
    "    seq_len= 128,\n",
    "    dataset='../fineweb-edu', \n",
    "    split=\"val\", \n",
    "    main_process=True,\n",
    ")\n",
    "\n",
    "def evaluate(model, val_steps = 5):\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "    val_loss = 0.0\n",
    "    torch_dtype = getattr(torch, 'bfloat16')\n",
    "    # val_steps = 5 # Abitrarily set to reduce long evaluations, >20 typically used\n",
    "    model.eval()\n",
    "    val_loader.reset()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm.tqdm(zip(range(val_steps), val_loader, strict=False)):\n",
    "            inputs, targets = batch\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            if torch_dtype != torch.float32:\n",
    "                with autocast(device_type=device.type, dtype=torch_dtype, cache_enabled=True):\n",
    "                    preds = model(inputs)\n",
    "            else:\n",
    "                preds = model(inputs)\n",
    "\n",
    "            loss = loss_fn(preds.flatten(0, 1), targets.flatten(0, 1))\n",
    "            loss = loss / val_steps\n",
    "            val_loss += loss.detach().float()\n",
    "    return(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d95e05c-8320-4061-85c8-3a62b9fee437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text for prompt 1: Obama is famous for\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:03<00:00, 53.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: Obama is famous for\n",
      "Generated Text: Obama is famous for his efforts to create a perfect union between the two countries, and for his efforts on behalf of the poor, the homeless and the disabled. He also worked to bring about the abolition of child labour and the abolition of child labour in the Indian economy. Both were very important in terms of his contribution to the Indian economy.\n",
      "The relationship between the two countries is not entirely harmonious, however. While some of the economic benefits accrued to the United States are obvious, others are more subtle. The United States is seen as a strong partner in providing basic necessities to the poor, while the Indian economy is seen as a weak partner. It is this dichotomy that has been the focus of much debate in recent years.\n",
      "The American Indian community, for example, is often portrayed as a negative force in the Indian economy. This is partly due to the fact that the Indian economy is viewed as a source of income for many Indians, and it is believed that Indian businesses are not taking advantage of this\n",
      "\n",
      "Tokens per second: 53.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Collect prompt(s) from user.\n",
    "# prompts = []\n",
    "# while True:\n",
    "#     prompt = input(\"Enter a prompt (press enter with no text to finish): \")\n",
    "#     if not prompt:\n",
    "#         break\n",
    "#     prompts.append(prompt.strip())\n",
    "\n",
    "#     if len(prompts) == 0:\n",
    "#         print(\"No prompts provided. Exiting.\")\n",
    "#         break\n",
    "\n",
    "prompts = ['Obama is famous for']\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# BASE SETTINGS:\n",
    "BASE_TEMPERATURE = 0.7  # Increase for more randomness.\n",
    "BASE_TOP_K = 50         # Limit sampling to the top k tokens.\n",
    "MAX_LENGTH = 200        # Maximum number of tokens to generate.\n",
    "# -------------------------------------------------------------------\n",
    "def generate_and_time(model, prompts, cache = True):\n",
    "    total_tokens = 0\n",
    "    start_time = time()\n",
    "    \n",
    "    for i, prompt in enumerate(prompts, 1):\n",
    "        print(f\"Generating text for prompt {i}: {prompt}\")\n",
    "        if cache:\n",
    "            model.setup_caches(batch_size = 1)\n",
    "        if not cache and model.caches_are_enabled():\n",
    "            model.reset_caches()\n",
    "            \n",
    "        generated_texts = generate_text(\n",
    "            model,\n",
    "            tokenizer,\n",
    "            prompt,\n",
    "            num_return_sequences=1,\n",
    "            max_length=MAX_LENGTH,\n",
    "            device=device,\n",
    "            temperature=BASE_TEMPERATURE,\n",
    "            top_k=BASE_TOP_K,\n",
    "            cache = cache\n",
    "        )\n",
    "        for gen_text in generated_texts:\n",
    "            print(f\"\\nPrompt: {prompt}\")\n",
    "            print(f\"Generated Text: {gen_text}\\n\")\n",
    "            total_tokens += len(\n",
    "                tokenizer.encode(gen_text, allowed_special={\"<|endoftext|>\"})\n",
    "            )\n",
    "        \n",
    "        if cache:\n",
    "            model.reset_caches()\n",
    "    \n",
    "    end_time = time()\n",
    "    tokens_per_second = total_tokens / (end_time - start_time)\n",
    "    print(f\"Tokens per second: {tokens_per_second:.2f}\")\n",
    "generate_and_time(model, prompts, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bb5728f-d4ba-4007-97fb-5df1b5ab1bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:04, 11.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.3545, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, val_steps = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9dd1089-bd32-444e-96d1-b716d84d198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from full_fast_stu import FullFastSTU\n",
    "import copy\n",
    "\n",
    "stu_before = []\n",
    "stu_after = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66ab57d6-201a-4e2b-8005-101a47b8c2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ds6237/stu_distill/experiments/convex_hull/full_fast_stu.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n"
     ]
    }
   ],
   "source": [
    "for idx in range(0, 12, 2):\n",
    "    stu_layer = copy.deepcopy(model.layers[idx].stu)\n",
    "    fast_layer = FullFastSTU(stu_layer.cuda(), \"../experiments/convex_hull/best_phi_lds.pt\").cuda()\n",
    "    model.layers[idx].stu = fast_layer\n",
    "\n",
    "    stu_before.append(stu_layer)\n",
    "    stu_after.append(fast_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5713d29-36bf-42dd-bf92-719a64aba6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text for prompt 1: Obama is famous for\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 50/196 [00:00<00:02, 67.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: Obama is famous for\n",
      "Generated Text: Obama is famous forICN  msba the of the of theouthms1 of the  of the, the of the, of the of the of the of the in the the and to see The of the, the of the of theas the if<|endoftext|>\n",
      "\n",
      "Tokens per second: 66.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_and_time(model, prompts, cache = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62ce7ef0-dffc-4ee7-aa3c-3a00b600684b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text for prompt 1: Obama is famous for\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_and_time(model, prompts, cache = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4f0b53c-611c-4ede-9c32-fd53abfd0584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0417, device='cuda:0', dtype=torch.bfloat16)\n",
      "tensor(0.3984, device='cuda:0', dtype=torch.bfloat16)\n",
      "tensor(0.3652, device='cuda:0', dtype=torch.bfloat16)\n",
      "tensor(0.4551, device='cuda:0', dtype=torch.bfloat16)\n",
      "tensor(1.1016, device='cuda:0', dtype=torch.bfloat16)\n",
      "tensor(3.2969, device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "gaps = []\n",
    "with torch.no_grad():\n",
    "    for i in range(6):\n",
    "        x = torch.randn(1,100,896).cuda()\n",
    "        input_pos = torch.arange(100, device=device)\n",
    "        \n",
    "        stu_out = stu_before[i](x.bfloat16(), input_pos)\n",
    "        lds_out = stu_after[i](x.bfloat16(), input_pos)\n",
    "        print(F.l1_loss(stu_out, lds_out))\n",
    "        gaps.append((stu_out - lds_out).abs().cpu().detach().float().flatten())\n",
    "        #F1 of approx 0.005 between stu with lds filters and lds. That's pretty high error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43968ab9-e845-460a-abd8-9a80e67dc369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_ = plt.hist(gaps, bins = 100, log = True)\n",
    "# plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88ee71ea-7178-4be2-a381-4fb758964ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0002, device='cuda:0', dtype=torch.bfloat16)\n",
      "tensor(0.0005, device='cuda:0', dtype=torch.bfloat16)\n",
      "tensor(0.0008, device='cuda:0', dtype=torch.bfloat16)\n",
      "tensor(0.0010, device='cuda:0', dtype=torch.bfloat16)\n",
      "tensor(0.0010, device='cuda:0', dtype=torch.bfloat16)\n",
      "tensor(0.0008, device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "gaps = []\n",
    "with torch.no_grad():\n",
    "    for i in range(6):\n",
    "        x = torch.randn(1,100,896).cuda()\n",
    "        input_pos = torch.arange(100, device=device)\n",
    "\n",
    "        stu_before[i].stu_filters = phi_cur\n",
    "        stu_out = stu_before[i](x.bfloat16(), input_pos)\n",
    "        \n",
    "        stu_before[i].stu_filters = phi_alt\n",
    "        lds_out = stu_before[i](x.bfloat16(), input_pos)\n",
    "        gaps.append((stu_out - lds_out).abs().cpu().detach().float().flatten())\n",
    "        print(F.l1_loss(stu_out, lds_out))\n",
    "        #F1 of approx 0.005 between stu with lds filters and lds. That's pretty high error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d3cb21f-ada7-4da0-bc41-d1bc5703bdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_ = plt.hist(gaps, bins = 100, log = True)\n",
    "# plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2d3f399-d9c8-43dd-9a77-aea38255179a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0,\n",
       " 2.682209e-07,\n",
       " 1.9073486e-06,\n",
       " 3.8146973e-06,\n",
       " 7.6293945e-06,\n",
       " 9.536743e-06,\n",
       " 1.1444092e-05,\n",
       " 1.4781952e-05,\n",
       " 1.5258789e-05,\n",
       " 1.7166138e-05,\n",
       " 1.9073486e-05,\n",
       " 2.193451e-05,\n",
       " 2.2888184e-05,\n",
       " 2.5749207e-05,\n",
       " 2.670288e-05,\n",
       " 3.0517578e-05,\n",
       " 3.2424927e-05,\n",
       " 3.4332275e-05,\n",
       " 3.6239624e-05,\n",
       " 3.8146973e-05,\n",
       " 4.5776367e-05,\n",
       " 4.7683716e-05,\n",
       " 4.9591064e-05,\n",
       " 5.340576e-05,\n",
       " 5.722046e-05,\n",
       " 6.1035156e-05,\n",
       " 6.484985e-05,\n",
       " 6.866455e-05,\n",
       " 7.247925e-05,\n",
       " 7.6293945e-05,\n",
       " 8.392334e-05,\n",
       " 9.1552734e-05,\n",
       " 9.918213e-05,\n",
       " 0.00010681152,\n",
       " 0.00011062622,\n",
       " 0.00011444092,\n",
       " 0.00012207031,\n",
       " 0.0001296997,\n",
       " 0.0001335144,\n",
       " 0.0001373291,\n",
       " 0.0001411438,\n",
       " 0.0001449585,\n",
       " 0.00014686584,\n",
       " 0.00015258789,\n",
       " 0.00016021729,\n",
       " 0.00016784668,\n",
       " 0.00017547607,\n",
       " 0.00018310547,\n",
       " 0.00019073486,\n",
       " 0.00019836426,\n",
       " 0.00020217896,\n",
       " 0.00021362305,\n",
       " 0.00021743774,\n",
       " 0.00022888184,\n",
       " 0.00024414062,\n",
       " 0.00025177002,\n",
       " 0.0002593994,\n",
       " 0.0002746582,\n",
       " 0.0002822876,\n",
       " 0.000289917,\n",
       " 0.0002975464,\n",
       " 0.00030517578,\n",
       " 0.00031280518,\n",
       " 0.00032043457,\n",
       " 0.00032806396,\n",
       " 0.00033569336,\n",
       " 0.00035095215,\n",
       " 0.00036621094,\n",
       " 0.00038146973,\n",
       " 0.00039672852,\n",
       " 0.0004119873,\n",
       " 0.0004272461,\n",
       " 0.0004348755,\n",
       " 0.00045776367,\n",
       " 0.00047302246,\n",
       " 0.00048828125,\n",
       " 0.00050354004,\n",
       " 0.00051116943,\n",
       " 0.0005187988,\n",
       " 0.000541687,\n",
       " 0.0005493164,\n",
       " 0.0005569458,\n",
       " 0.000579834,\n",
       " 0.00060653687,\n",
       " 0.00061035156,\n",
       " 0.00062561035,\n",
       " 0.00064086914,\n",
       " 0.00065612793,\n",
       " 0.0006713867,\n",
       " 0.0006866455,\n",
       " 0.0007019043,\n",
       " 0.0007324219,\n",
       " 0.00074768066,\n",
       " 0.00076293945,\n",
       " 0.00079345703,\n",
       " 0.0008087158,\n",
       " 0.0008239746,\n",
       " 0.0008544922,\n",
       " 0.00088500977,\n",
       " 0.00091552734,\n",
       " 0.00093078613,\n",
       " 0.0009460449,\n",
       " 0.0009765625,\n",
       " 0.0009918213,\n",
       " 0.0010223389,\n",
       " 0.0010375977,\n",
       " 0.0010528564,\n",
       " 0.0010681152,\n",
       " 0.001083374,\n",
       " 0.0010986328,\n",
       " 0.0011138916,\n",
       " 0.0011291504,\n",
       " 0.0011444092,\n",
       " 0.001159668,\n",
       " 0.0011901855,\n",
       " 0.0012207031,\n",
       " 0.0012512207,\n",
       " 0.0012817383,\n",
       " 0.0013427734,\n",
       " 0.0013504028,\n",
       " 0.001373291,\n",
       " 0.0014038086,\n",
       " 0.0014648438,\n",
       " 0.0014801025,\n",
       " 0.0015106201,\n",
       " 0.0015258789,\n",
       " 0.0015869141,\n",
       " 0.0016174316,\n",
       " 0.0016479492,\n",
       " 0.0016708374,\n",
       " 0.0016784668,\n",
       " 0.0016937256,\n",
       " 0.0017089844,\n",
       " 0.0017700195,\n",
       " 0.0018310547,\n",
       " 0.0018463135,\n",
       " 0.0018920898,\n",
       " 0.0019378662,\n",
       " 0.001953125,\n",
       " 0.0019836426,\n",
       " 0.0020141602,\n",
       " 0.0020446777,\n",
       " 0.0020751953,\n",
       " 0.0021209717,\n",
       " 0.0021362305,\n",
       " 0.002166748,\n",
       " 0.0021972656,\n",
       " 0.0022277832,\n",
       " 0.0022583008,\n",
       " 0.002319336,\n",
       " 0.0024108887,\n",
       " 0.0024414062,\n",
       " 0.0024719238,\n",
       " 0.0025634766,\n",
       " 0.0026855469,\n",
       " 0.002746582,\n",
       " 0.0028076172,\n",
       " 0.0029296875,\n",
       " 0.0030517578,\n",
       " 0.0031738281,\n",
       " 0.0032348633,\n",
       " 0.0032958984,\n",
       " 0.0033569336,\n",
       " 0.0034179688,\n",
       " 0.003540039,\n",
       " 0.0036621094,\n",
       " 0.00390625,\n",
       " 0.003967285,\n",
       " 0.0040893555,\n",
       " 0.0041503906,\n",
       " 0.004333496,\n",
       " 0.0043945312,\n",
       " 0.0045166016,\n",
       " 0.004638672,\n",
       " 0.004760742,\n",
       " 0.0048828125,\n",
       " 0.005065918,\n",
       " 0.005126953,\n",
       " 0.0053710938,\n",
       " 0.0056152344,\n",
       " 0.005859375,\n",
       " 0.0061035156,\n",
       " 0.0063476562,\n",
       " 0.0068359375,\n",
       " 0.0073242188,\n",
       " 0.0075683594,\n",
       " 0.0076904297,\n",
       " 0.0078125,\n",
       " 0.0087890625,\n",
       " 0.009643555,\n",
       " 0.009765625,\n",
       " 0.010253906,\n",
       " 0.0107421875,\n",
       " 0.01171875,\n",
       " 0.012207031,\n",
       " 0.0126953125,\n",
       " 0.013671875,\n",
       " 0.015625,\n",
       " 0.016601562,\n",
       " 0.017578125,\n",
       " 0.0234375,\n",
       " 0.03125,\n",
       " 0.0625,\n",
       " 0.125,\n",
       " 0.25}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(torch.cat(gaps).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e47f37f5-7c47-4238-a0b6-43ec0090b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So the error is induced by the LDS approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ac9b2dc-c567-4e8a-b32b-ac53bf0628a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Model 0, Loss: 3.3080577850341797e-06\n",
      "Iteration 2, Model 0, Loss: 3.4421682357788086e-06\n",
      "Iteration 3, Model 0, Loss: 3.3080577850341797e-06\n",
      "Iteration 4, Model 0, Loss: 3.769993782043457e-06\n",
      "Iteration 5, Model 0, Loss: 3.069639205932617e-06\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Use .float() instead of .bfloat16() for better stability in training\u001b[39;00m\n\u001b[1;32m     19\u001b[0m stu_out \u001b[38;5;241m=\u001b[39m stu_before[i](x\u001b[38;5;241m.\u001b[39mbfloat16(), input_pos)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m---> 20\u001b[0m lds_out \u001b[38;5;241m=\u001b[39m stu_after[i](x\u001b[38;5;241m.\u001b[39mbfloat16(), input_pos)\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(stu_out, lds_out)\n\u001b[1;32m     24\u001b[0m optimizers[i]\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Clear previous gradients\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/torch-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/stu_distill/experiments/convex_hull/full_fast_stu.py:78\u001b[0m, in \u001b[0;36mFullFastSTU.forward\u001b[0;34m(self, x, input_pos)\u001b[0m\n\u001b[1;32m     76\u001b[0m bsz \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     77\u001b[0m x_reshaped \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [B*d_in, L, 1]\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m U_reshaped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlds(x_reshaped) \u001b[38;5;66;03m# [B*d_in, L, K]\u001b[39;00m\n\u001b[1;32m     79\u001b[0m U \u001b[38;5;241m=\u001b[39m U_reshaped\u001b[38;5;241m.\u001b[39mreshape(bsz, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_approx:\n",
      "File \u001b[0;32m~/.conda/envs/torch-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/torch-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/stu_distill/src/lds.py:38\u001b[0m, in \u001b[0;36mLDS.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     35\u001b[0m all_h_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(all_h_t, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     36\u001b[0m lds_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(all_h_t, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC)\n\u001b[0;32m---> 38\u001b[0m ar \u001b[38;5;241m=\u001b[39m compute_ar_x_preds(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM, inputs)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lds_out \u001b[38;5;241m+\u001b[39m ar\n",
      "File \u001b[0;32m~/stu_distill/src/lds_utils.py:52\u001b[0m, in \u001b[0;36mcompute_ar_x_preds\u001b[0;34m(w, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m             w_k \u001b[38;5;241m=\u001b[39m w[:, :, k]  \u001b[38;5;66;03m# Shape: [d_out, d_in]\u001b[39;00m\n\u001b[1;32m     51\u001b[0m             \u001b[38;5;66;03m# Compute the matrix multiplication using torch operations\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m             ar_pred[:, t, :] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m x_t_minus_k \u001b[38;5;241m@\u001b[39m w_k\u001b[38;5;241m.\u001b[39mt()\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ar_pred\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Ensure all parameters in stu_after are trainable\n",
    "for pm in stu_after:\n",
    "    for param in pm.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Optimizers for each model\n",
    "optimizers = [Adam(stu_after[i].parameters(), lr=1e-6) for i in range(6)]\n",
    "\n",
    "for i in range(6):\n",
    "    for epoch in range(100):  # Number of optimization steps\n",
    "        x = torch.randn(1, 100, 896).cuda()\n",
    "        input_pos = torch.arange(100, device='cuda')\n",
    "        \n",
    "        # Use .float() instead of .bfloat16() for better stability in training\n",
    "        stu_out = stu_before[i](x.bfloat16(), input_pos).detach()\n",
    "        lds_out = stu_after[i](x.bfloat16(), input_pos)\n",
    "        \n",
    "        loss = F.mse_loss(stu_out, lds_out)\n",
    "        \n",
    "        optimizers[i].zero_grad()  # Clear previous gradients\n",
    "        loss.backward()           # Backpropagation\n",
    "        optimizers[i].step()      # Gradient descent step\n",
    "        \n",
    "        print(f\"Iteration {epoch + 1}, Model {i}, Loss: {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env [~/.conda/envs/torch-env/]",
   "language": "python",
   "name": "conda_torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
